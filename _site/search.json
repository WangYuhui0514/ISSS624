[
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangling geospatial data using appropriate R packages.\n\n\n\nThe code chunk below install and load sf and tidyverse packages into R environment\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\n\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n\n\n\n\n\n\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3483 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\n\n\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\n\n\n\n\n\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\n\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#overview",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#overview",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n2.1.1 Survival Tip\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#getting-start",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#getting-start",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "The code chunk below install and load sf and tidyverse packages into R environment\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#importing-geospatial-data",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "mpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to ISSS624 Geospatial Analytics Applications!\nIn this webpage, I am going to share with you my learning journey of geospatial"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "st_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "plot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#working-with-projection",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#working-with-projection",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "st_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "listings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3483 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\n\n\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "buffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\n\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#explorotary-data-analysis-eda",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#explorotary-data-analysis-eda",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "hist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Exercise_1.html",
    "href": "Take-Home_Exercise_1/Take-Home_Exercise_1.html",
    "title": "Take-Home_Exercise_1:Geospatial Analytics for Social Good",
    "section": "",
    "text": "As urban transportation and infrastructure become digitized, the resulting data sets can be used as a framework for crafting patterns of movement in space and time. These large amounts of motion data collected may contain structures and patterns that provide useful information about the characteristics of the measured phenomena. The identification, analysis and comparison of these patterns will provide deeper insights into how people move and behave within cities. These understandings will potentially contribute to better urban management and provide useful information to private and public sector urban transport service providers to make informed decisions to gain a competitive advantage.\n\n\nExploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThis study mainly uses three methods：\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualisation methods,\nDescribe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).\n\n\n\n\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).\n\n\n\n\n\nThe focus of this study will be Singapore. Singapore’s public transport system is renowned for its efficient, clean, safe and timely services. The city has a comprehensive digital public transportation network that is optimized through advanced information technology and big data analytics to improve operational efficiency and passenger experience.\nSingapore’s urban infrastructure, such as utilities and roads, is also highly digitalized, using sensors, the Internet of Things (IoT) and other advanced technologies to monitor and manage city operations. For example, through vehicles equipped with GPS and RFID, traffic flows and patterns can be tracked, which helps in real-time traffic management and planning.\nThese digitalization measures enable Singapore to make important progress in improving the efficiency of public services, promoting sustainable development and enhancing the quality of life of residents."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Exercise_1.html#objectives-and-methods",
    "href": "Take-Home_Exercise_1/Take-Home_Exercise_1.html#objectives-and-methods",
    "title": "Take-Home_Exercise_1:Geospatial Analytics for Social Good",
    "section": "",
    "text": "Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThis study mainly uses three methods：\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualisation methods,\nDescribe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).\n\n\n\n\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster)."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Exercise_1.html#study-area",
    "href": "Take-Home_Exercise_1/Take-Home_Exercise_1.html#study-area",
    "title": "Take-Home_Exercise_1:Geospatial Analytics for Social Good",
    "section": "",
    "text": "The focus of this study will be Singapore. Singapore’s public transport system is renowned for its efficient, clean, safe and timely services. The city has a comprehensive digital public transportation network that is optimized through advanced information technology and big data analytics to improve operational efficiency and passenger experience.\nSingapore’s urban infrastructure, such as utilities and roads, is also highly digitalized, using sensors, the Internet of Things (IoT) and other advanced technologies to monitor and manage city operations. For example, through vehicles equipped with GPS and RFID, traffic flows and patterns can be tracked, which helps in real-time traffic management and planning.\nThese digitalization measures enable Singapore to make important progress in improving the efficiency of public services, promoting sustainable development and enhancing the quality of life of residents."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Exercise_1.html#setting-the-analytical-tools",
    "href": "Take-Home_Exercise_1/Take-Home_Exercise_1.html#setting-the-analytical-tools",
    "title": "Take-Home_Exercise_1:Geospatial Analytics for Social Good",
    "section": "2.1 Setting the Analytical Tools",
    "text": "2.1 Setting the Analytical Tools\nThe code chunk below installs and loads sf, spdep, tmap, ggplot2, tidyverse, patchwork, tidyverse, readr packages into R environment. pacman() is a R package management tool.\n\npacman::p_load(sf, spdep, tmap, ggplot2, tidyverse, patchwork, tidyverse, readr)\n\n1"
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall."
  },
  {
    "objectID": "In-Class_Ex_3/data/geospatial/MPSZ-2019.html",
    "href": "In-Class_Ex_3/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#importing-the-od-data",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#importing-the-od-data",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "3.1 Importing the OD data",
    "text": "3.1 Importing the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\n\nShow the code\nodbus &lt;- read_csv(\"data/origin_destination_bus_202310.csv\")\n\n\nRows: 5694297 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nShow the code\nglimpse(odbus)\n\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nA quick check of odbus tibble data frame shows that the values in OROGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\n\nShow the code\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)"
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#extracting-the-study-data",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#extracting-the-study-data",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "3.2 Extracting the study data",
    "text": "3.2 Extracting the study data\nFor the purpose of this exercise, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\n\nShow the code\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nTable below shows the content of odbus6_9\n\ndatatable(odbus6_9)\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\n\nSave the output in rds format for future used.\n\n\nShow the code\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\n\n\nImport the save odbus6_9.rds into R environment.\n\n\nShow the code\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#coverview",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#coverview",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangling geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#getting-started",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#getting-started",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#importing-data-into-r",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#importing-data-into-r",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.3 Importing Data into R",
    "text": "2.3 Importing Data into R\n\n2.3.1 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n2.3.2 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.3.3 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.3.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\npopdata2020\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Cen…  1440             2610   760  4810      0.843\n 2 Ang Mo Kio Cheng San             6640            15460  6050 28150      0.821\n 3 Ang Mo Kio Chong Boon            6150            13950  6470 26570      0.905\n 4 Ang Mo Kio Kebun Bahru           5540            12090  5120 22750      0.882\n 5 Ang Mo Kio Sembawang Hills       2100             3410  1310  6820      1    \n 6 Ang Mo Kio Shangri-La            3960             8420  3610 15990      0.899\n 7 Ang Mo Kio Tagore                2220             4200  1530  7950      0.893\n 8 Ang Mo Kio Townsville            4690            11450  5100 21240      0.855\n 9 Ang Mo Kio Yio Chu Kang             0                0     0     0    NaN    \n10 Ang Mo Kio Yio Chu Kang East     1220             2300   750  4270      0.857\n# ℹ 322 more rows\n\n\n\n\n2.3.3.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\npopdata2020\n\n# A tibble: 234 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 ANG MO KIO ANG MO KIO TOWN CEN…  1440             2610   760  4810      0.843\n 2 ANG MO KIO CHENG SAN             6640            15460  6050 28150      0.821\n 3 ANG MO KIO CHONG BOON            6150            13950  6470 26570      0.905\n 4 ANG MO KIO KEBUN BAHRU           5540            12090  5120 22750      0.882\n 5 ANG MO KIO SEMBAWANG HILLS       2100             3410  1310  6820      1    \n 6 ANG MO KIO SHANGRI-LA            3960             8420  3610 15990      0.899\n 7 ANG MO KIO TAGORE                2220             4200  1530  7950      0.893\n 8 ANG MO KIO TOWNSVILLE            4690            11450  5100 21240      0.855\n 9 ANG MO KIO YIO CHU KANG EAST     1220             2300   750  4270      0.857\n10 ANG MO KIO YIO CHU KANG WEST     6590            12850  4680 24120      0.877\n# ℹ 224 more rows\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.4 Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n2.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n2.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n2.4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n2.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nparameters of style can be fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\n\n2.4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n2.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n2.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n2.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"natural\")\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n2.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n2.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n2.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex_1/Hands-on_Ex_1.html#reference",
    "href": "Hands-on_Ex_1/Hands-on_Ex_1.html#reference",
    "title": "Hands-on Exercise 1:Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.5 Reference",
    "text": "2.5 Reference\n\n2.5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n2.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n2.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban transportation and infrastructure become digitized, the resulting data sets can be used as a framework for crafting patterns of movement in space and time. These large amounts of motion data collected may contain structures and patterns that provide useful information about the characteristics of the measured phenomena. The identification, analysis and comparison of these patterns will provide deeper insights into how people move and behave within cities. These understandings will potentially contribute to better urban management and provide useful information to private and public sector urban transport service providers to make informed decisions to gain a competitive advantage.\n\n\nExploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThis study mainly uses three methods：\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualization methods,\nDescribe the spatial patterns revealed by the geovisualization (not more than 200 words per visual).\n\n\n\n\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualization prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).\n\n\n\n\n\nThe focus of this study will be Singapore. Singapore’s public transport system is renowned for its efficient, clean, safe and timely services. The city has a comprehensive digital public transportation network that is optimized through advanced information technology and big data analytics to improve operational efficiency and passenger experience.\nSingapore’s urban infrastructure, such as utilities and roads, is also highly digitalized, using sensors, the Internet of Things (IoT) and other advanced technologies to monitor and manage city operations. For example, through vehicles equipped with GPS and RFID, traffic flows and patterns can be tracked, which helps in real-time traffic management and planning.\nThese digitalization measures enable Singapore to make important progress in improving the efficiency of public services, promoting sustainable development and enhancing the quality of life of residents."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#objectives-and-methods",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#objectives-and-methods",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThis study mainly uses three methods：\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualization methods,\nDescribe the spatial patterns revealed by the geovisualization (not more than 200 words per visual).\n\n\n\n\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualization prepared, describe the spatial patterns reveled. (not more than 250 words per cluster)."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#study-area",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#study-area",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "The focus of this study will be Singapore. Singapore’s public transport system is renowned for its efficient, clean, safe and timely services. The city has a comprehensive digital public transportation network that is optimized through advanced information technology and big data analytics to improve operational efficiency and passenger experience.\nSingapore’s urban infrastructure, such as utilities and roads, is also highly digitalized, using sensors, the Internet of Things (IoT) and other advanced technologies to monitor and manage city operations. For example, through vehicles equipped with GPS and RFID, traffic flows and patterns can be tracked, which helps in real-time traffic management and planning.\nThese digitalization measures enable Singapore to make important progress in improving the efficiency of public services, promoting sustainable development and enhancing the quality of life of residents."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#setting-the-analytical-tools",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#setting-the-analytical-tools",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.1 Setting the Analytical Tools",
    "text": "2.1 Setting the Analytical Tools\nThe code chunk below installs and loads sf, sfdep, magrittr, tidyverse, tmap, knitr, RColorBrewer, viridis packages into R environment. pacman() is a R package management tool.\n\npacman::p_load(sf, sfdep, magrittr, tidyverse, tmap, knitr, RColorBrewer, viridis, dplyr)"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#importing-data",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#importing-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nWe will import the data as a first step before proceeding with data cleaning, data wrangling and data exploration for the following:\nPassenger Volume\nPassengerVolume is an aspatial data, we can import the data simply by using the read_csv function from tidyverse package and output it as a tibble dataframe called odbus\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\nRows: 5694297 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBus Stop Location\nBus Stop is a geospatial data in .shp file. We save it as a sf data frame called busstop using the st_read function of the sf package. The data is then geo-referenced to coordinates from the Singapore SVY21 coordinate system (EPSG: 3414)\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `BusStop' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Take-Home_Exercise_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#data-wrangling",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#data-wrangling",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Passenger Volume\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nSince we plan to use the bus stop code as a unique identifier when joining with other datasets, change it to a factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nChecking for Duplicates and Missing Data\n\nduplicate &lt;- odbus %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\n\nsummary(odbus)\n\n  YEAR_MONTH          DAY_TYPE         TIME_PER_HOUR     PT_TYPE         \n Length:5694297     Length:5694297     Min.   : 0.00   Length:5694297    \n Class :character   Class :character   1st Qu.:10.00   Class :character  \n Mode  :character   Mode  :character   Median :14.00   Mode  :character  \n                                       Mean   :14.04                     \n                                       3rd Qu.:18.00                     \n                                       Max.   :23.00                     \n                                                                         \n ORIGIN_PT_CODE    DESTINATION_PT_CODE  TOTAL_TRIPS      \n 22009  :  17444   22009  :  17328     Min.   :    1.00  \n 84009  :  16842   84009  :  16808     1st Qu.:    2.00  \n 52009  :  16734   52009  :  16253     Median :    4.00  \n 75009  :  16610   75009  :  16143     Mean   :   20.76  \n 59009  :  14991   59009  :  15134     3rd Qu.:   12.00  \n 46009  :  14642   46009  :  14167     Max.   :36668.00  \n (Other):5597034   (Other):5598464                       \n\n\nThere is no missing data or duplicates."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#classify-peak-hours",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#classify-peak-hours",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.4 Classify peak hours",
    "text": "2.4 Classify peak hours\nAccording to the time interval specified in the task, calculate the passenger travel volume generated at the departure place. Passenger itineraries by origin are saved in 4 data frames according to their respective classifications, namely:\nWeekday morning peak\nWeekday afternoon peak\nWeekend morning peak\nWeekend evening peak\nSave the processed data to a .rds data format file. Output files are saved in the rds subfolder. This is done to reduce load times and keep large raw files from being uploaded to GitHub.\n\n\nShow the code\nweekday_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekday_afternoon_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekend_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekend_evening_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nwrite_rds(weekday_morning_peak, \"data/rds/weekday_morning_peak.rds\")\nweekday_morning_peak &lt;- read_rds(\"data/rds/weekday_morning_peak.rds\")\n\nwrite_rds(weekday_afternoon_peak, \"data/rds/weekday_afternoon_peak.rds\")\nweekday_afternoon_peak &lt;- read_rds(\"data/rds/weekday_afternoon_peak.rds\")\n\nwrite_rds(weekend_morning_peak, \"data/rds/weekend_morning_peak.rds\")\nweekend_morning_peak &lt;- read_rds(\"data/rds/weekend_morning_peak.rds\")\n\nwrite_rds(weekend_evening_peak, \"data/rds/weekend_evening_peak.rds\")\nweekend_evening_peak &lt;- read_rds(\"data/rds/weekend_evening_peak.rds\")"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#creating-hexagon-data",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#creating-hexagon-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.5 Creating Hexagon Data",
    "text": "2.5 Creating Hexagon Data\nCreate Hexagon Dataset from busstop\n\nhexagon = st_make_grid(busstop, c(250, 250), what = \"polygons\", square = FALSE)\nhexagon_sf = st_sf(hexagon) %&gt;%\n  mutate(grid_id = 1:length(lengths(hexagon)))\n\nExamine the Grid\n\nhexagon_sf$coll &lt;- lengths(st_intersects(hexagon_sf, busstop))\nprint(n_distinct(hexagon_sf$grid_id))\n\n[1] 22134\n\nprint(sum(hexagon_sf$coll == 0))\n\n[1] 19003\n\nsummary(hexagon_sf$coll)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.2332  0.0000  5.0000 \n\n\nThere are 22134 grids and 19003 grids with zero bus stops, a max of 5 bus stops per grid.\nDelete hexagonal data with zero bus stops\n\nhexagon_sf = filter(hexagon_sf, coll &gt; 0)\nwrite_rds(hexagon_sf, \"data/rds/hexagon_sf.rds\")\nhexagon_sf &lt;- read_rds(\"data/rds/hexagon_sf.rds\")"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.6 Visualizing",
    "text": "2.6 Visualizing\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nmap_busstopcounts = tm_shape(hexagon_sf) +\n  tm_fill(\n    col = \"coll\",\n    palette = c(\"grey\",rev(viridis(6))),\n    breaks = c(0, 1, 2, 3, 4, 5),\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 1,\n    popup.vars = c(\n      \"Number of collisions: \" = \"coll\"\n    ),\n    popup.format = list(\n      coll = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"black\", lwd = 0.2)\n\nmap_busstopcounts\n\n\n\n\n\nFrom the picture we can see:\nThere is no bus station in the central area, probably because there is a reservoir.\nThere are very few bus stops in the northwest, probably because there is a farm."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#combining-the-data",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#combining-the-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.7 Combining the Data",
    "text": "2.7 Combining the Data\n\n\nShow the code\n# Define a function to merge and summarize data\nmerge_and_summarize &lt;- function(time_peak_data, busstop_hexagon, hexagon_sf) {\n  join_list &lt;- left_join(time_peak_data, busstop_hexagon, by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n    rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_GRID = grid_id) %&gt;%\n    group_by(ORIGIN_GRID) %&gt;%\n    summarise(TOT_TRIPS = sum(TRIPS))\n\n  join_geometry &lt;- left_join(hexagon_sf, join_list, by = c(\"grid_id\" = \"ORIGIN_GRID\"))\n  return(join_geometry)\n}\n\n# List to store different time period data\ntime_peaks &lt;- list(\n  weekday_morning_peak,\n  weekday_afternoon_peak,\n  weekend_morning_peak,\n  weekend_evening_peak\n)\n\n# Merge bus stop and hexagonal grid\nbusstop_hexagon &lt;- st_intersection(busstop, hexagon_sf) %&gt;%\n  select(BUS_STOP_N, grid_id) %&gt;%\n  st_drop_geometry\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nShow the code\n# Apply the function to each time period\nresults &lt;- lapply(time_peaks, function(data) merge_and_summarize(data, busstop_hexagon, hexagon_sf))\n\n# Save the results in RDS format\nfile_names &lt;- c(\"weekday_morning_peak_join_geometry.rds\",\n                \"weekday_afternoon_peak_join_geometry.rds\",\n                \"weekend_morning_peak_join_geometry.rds\",\n                \"weekend_evening_peak_join_geometry.rds\")\n\nfor (i in seq_along(results)) {\n  write_rds(results[[i]], paste0(\"data/rds/\", file_names[i]))\n}"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#distribution-of-total-trips-and-trips-per-bus-stop",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#distribution-of-total-trips-and-trips-per-bus-stop",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "3.1 Distribution of total trips and trips per bus stop",
    "text": "3.1 Distribution of total trips and trips per bus stop\n\n\nShow the code\nrds_path &lt;- \"data/rds/\"\nweekday_morning_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekday_morning_peak_join_geometry.rds\"))\nweekday_afternoon_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekday_afternoon_peak_join_geometry.rds\"))\nweekend_morning_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekend_morning_peak_join_geometry.rds\"))\nweekend_evening_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekend_evening_peak_join_geometry.rds\"))\n\n\n\n\ncombined_data &lt;- bind_rows(\n  weekday_morning_peak_join_geometry %&gt;% mutate(period = \"Weekday Morning Peak\"),\n  weekday_afternoon_peak_join_geometry %&gt;% mutate(period = \"Weekday Afternoon Peak\"),\n  weekend_morning_peak_join_geometry %&gt;% mutate(period = \"Weekend Morning Peak\"),\n  weekend_evening_peak_join_geometry %&gt;% mutate(period = \"Weekend Evening Peak\")\n)\n\n\n# Plot combined data\nggplot(data = combined_data, \n       aes(x = as.numeric(`TOT_TRIPS`))) +\n  geom_histogram(bins = 20, \n                 color = \"blue\", \n                 fill = \"blue\") +\n  facet_wrap(~period, scales = \"free_y\") +\n  labs(title = \"Distribution of Passenger Trips during Different Time Periods\",\n       x = \"Total Trips\",\n       y = \"Frequency\")\n\n\nWarning: Removed 337 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\nShow the code\nlibrary(ggplot2)\n\ncombined_dsitribution &lt;- combined_data %&gt;%\n  mutate(`trips_per_busstop` = (`TOT_TRIPS` / coll))\n\nggplot(data = combined_dsitribution, aes(x = as.numeric(`trips_per_busstop`))) +\n  geom_histogram(bins = 20, color = \"blue\", fill = \"blue\") +\n  facet_wrap(~period, scales = \"free_y\") +\n  labs(title = \"Distribution of Passenger Trips during Different Time Periods\",\n       x = \"Total Trips Per BusStop\",\n       y = \"Frequency\") +\n  theme_minimal() \n\n\nWarning: Removed 337 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#distribution-across-4-time-periods",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#distribution-across-4-time-periods",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "3.2 Distribution Across 4 Time Periods",
    "text": "3.2 Distribution Across 4 Time Periods\n\n\nShow the code\nggplot(combined_data, aes(x = factor(period), y = TOT_TRIPS)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = \"blue\") +\n  labs(title = \"Distribution Across 4 Time Periods\",\n       x = \"Time Period\",\n       y = \"Total Trips\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\nWarning: Removed 337 rows containing missing values (`geom_bar()`).\n\n\n\n\n\nThrough the above analysis, it is found that the number of trips during the morning peak on weekdays is the largest, followed by the afternoon peak on weekdays, the morning peak on weekends, and finally the evening peak on weekends.\nPublic transportation authorities can use this information to better allocate personnel and public transportation resources."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#calculating-adaptive-distance-weights",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#calculating-adaptive-distance-weights",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.1 Calculating adaptive distance weights",
    "text": "5.1 Calculating adaptive distance weights\nBecause the minimum, median, mean, and 75th percentile are all 250 . Therefore we set k=1 when generating weights.\n\ngeo &lt;- sf::st_geometry(hexagon_sf)\nneighbour &lt;- st_knn(geo, longlat = TRUE)\n\n! Polygon provided. Using point on surface.\n\ndists &lt;- unlist(st_nb_dists(geo, neighbour))\n\n! Polygon provided. Using point on surface.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  250.0   250.0   250.0   259.6   250.0  4250.0 \n\n\n\n\nShow the code\nprocess_data &lt;- function(data, hexagon) {\n  data %&gt;%\n    mutate(TOT_TRIPS = replace_na(TOT_TRIPS, 0), \n           neighbour = st_knn(hexagon, k = 1),\n           wt = st_weights(neighbour, style = \"W\", allow_zero = TRUE),\n           .before = 1)\n}\nwm_q_1 &lt;- process_data(weekday_morning_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface.\n\n\nShow the code\nwm_q_2 &lt;- process_data(weekday_afternoon_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface.\n\n\nShow the code\nwm_q_3 &lt;- process_data(weekend_morning_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface.\n\n\nShow the code\nwm_q_4 &lt;- process_data(weekend_evening_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#calculating-local-morans-i-space-autocorrelation-statistics",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#calculating-local-morans-i-space-autocorrelation-statistics",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.2 Calculating local Moran’s I space autocorrelation statistics",
    "text": "5.2 Calculating local Moran’s I space autocorrelation statistics\nThe analysis focuses on the spatial autocorrelation of the variable TOT_TRIPS in each dataset, using the local_moran function for 99 simulations.\nMoran’s I spatial autocorrelation statistic is calculated to evaluate whether nearby observations exhibit similar total travel values, revealing spatial patterns and clustering.\n\n\nShow the code\ncompute_local_moran_I &lt;- function(df) {\n  df %&gt;% \n    mutate(local_moran = local_moran(TOT_TRIPS, neighbour, wt, nsim = 99), .before = 1) %&gt;%\n    unnest(local_moran)\n}\n\n# List of data frames\nwm_qs &lt;- list(wm_q_1, wm_q_2, wm_q_3, wm_q_4)\n\n# Apply the function to each data frame\nlisa_results &lt;- lapply(wm_qs, compute_local_moran_I)\n\nlisa_1 &lt;- lisa_results[[1]]\nlisa_2 &lt;- lisa_results[[2]]\nlisa_3 &lt;- lisa_results[[3]]\nlisa_4 &lt;- lisa_results[[4]]"
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing-1",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing-1",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.3 visualizing",
    "text": "5.3 visualizing\nIn the following code chunk, a partitioned chart is created based on local Moran’s I values. Positive Local Moran’s I values indicate a feature’s membership in a cluster, while negative values indicate that the feature is an outlier. Areas in various shades of green indicate their membership in one or more clusters.\nHowever, relying solely on the local Moran score is not sufficient to describe spatial clustering, as it cannot provide information about whether the total number of passengers’ trips is high or low and whether the test results are statistically significant. We need to continue analyzing only areas where total passenger trips have statistically significant values.\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekday morning\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_2) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekday afternoon\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_3) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekend morning\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_4) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekend afternoon\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing-p-value-of-local-morans-i",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing-p-value-of-local-morans-i",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.4 visualizing p-value of local Moran’s I",
    "text": "5.4 visualizing p-value of local Moran’s I\nIn the following code chunk below, only statistically significant local Moran’s I values (p_ii_sim &lt; 0.05) are visualized.\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekday morning\",\n            main.title.size = 1.2,\n            main.title.position = \"center\" ) +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_2) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekday afternoon\",\n            main.title.size = 1.2,\n            main.title.position = \"center\") +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_3) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekend morning\",\n            main.title.size = 1.2,\n            main.title.position = \"center\") +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_4) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekend afternoon\",\n            main.title.size = 1.2,\n            main.title.position = \"center\") +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing-lisa-map",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#visualizing-lisa-map",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.5 Visualizing LISA map",
    "text": "5.5 Visualizing LISA map\nIn the following code chunk, LISA divides each region into four groups:\nHigh - High means that a grid with a high number of initial trips is next to other grids with a high number of initial trips.\nHigh-Low means grids with more initial trips are next to other grids with fewer initial trips\nLow - Low means that a grid with a low number of initial strokes is next to other grids with a low number of initial strokes\nLow-High means that grids with fewer initial trips are located next to other grids with more initial trips.\n\n5.5.1 Weekday morning peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_1  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n5.5.2 Weekday afternoon peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_2  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n5.5.3 Weekend morning peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_3  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n5.5.4 Weekend afternoon peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_4  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Take-Home_Exercise_1/Take-Home_Ex_1.html#conclusion",
    "href": "Take-Home_Exercise_1/Take-Home_Ex_1.html#conclusion",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.6 Conclusion",
    "text": "5.6 Conclusion\nHigh-High: In these areas, places with high travel demand are often close to each other, forming obvious travel hotspots. These hotspots may correspond to business centers, residential areas, or other places where activity is concentrated.\nLow-Low: Areas with low travel demand are relatively scattered and do not form large continuous low-demand areas. These may be more remote or inaccessible areas.\nHigh-Low: Represents areas adjacent to high travel areas but with low travel demand. This can happen at the edges of busy areas, or in areas where travel demand has dropped for specific reasons, such as transport planning or geographical constraints.\nLow-High: Indicates that although some areas have low travel demand, they are close to areas with concentrated travel demand. This may be due to superior geographical location but underdevelopment.\nAs can be seen from the four pictures above, the High-Low and Low-High areas are mainly located in the northeast and south-central part, indicating that there is still room for improvement in the public transportation planning of these two areas."
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#importing-geospatial-data",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#importing-geospatial-data",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "4.1 Importing geospatial data",
    "text": "4.1 Importing geospatial data\nTwo geospatial data will be used in this exercise, they are:\n\n\nShow the code\nbusstop &lt;- st_read(dsn = \"data/geospatial/\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `BusStop' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_3/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\nShow the code\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_3/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\nShow the code\nmpsz\n\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\nShow the code\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#combining-busstop-and-mpsz",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#combining-busstop-and-mpsz",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "5.1 Combining Busstop and mpsz",
    "text": "5.1 Combining Busstop and mpsz\n\n\nShow the code\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\n\nShow the code\ndatatable(busstop_mpsz)\n\n\n\n\n\n\n\n\n\nShow the code\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\n\nShow the code\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\n\nWarning in left_join(odbus6_9, busstop_mpsz, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 60989 of `x` matches multiple rows in `y`.\nℹ Row 672 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nBefore continue, it is a good practice for us to check for duplicating records.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n# A tibble: 1,022 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 22501     22009         1 JWSZ09   \n 2 22501     22009         1 JWSZ09   \n 3 22501     22451       167 JWSZ09   \n 4 22501     22451       167 JWSZ09   \n 5 22501     22469        28 JWSZ09   \n 6 22501     22469        28 JWSZ09   \n 7 22501     22479        20 JWSZ09   \n 8 22501     22479        20 JWSZ09   \n 9 22501     22509         4 JWSZ09   \n10 22501     22509         4 JWSZ09   \n# ℹ 1,012 more rows\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\nNext, we will update od_data data frame cwith the planning subzone codes.\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_data, busstop_mpsz, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 167 of `x` matches multiple rows in `y`.\nℹ Row 671 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nod_data &lt;- unique(od_data)\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nNext, save the data.\n\nwrite_rds(od_data, \"data/rds/od_data.rds\")\n\nod_data &lt;- read_rds(\"data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#removing-intra-zonal-flows",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#removing-intra-zonal-flows",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "6.1 Removing intra-zonal flows",
    "text": "6.1 Removing intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]"
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#creating-desire-lines",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#creating-desire-lines",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "6.2 Creating desire lines",
    "text": "6.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points."
  },
  {
    "objectID": "Hands-on_Ex_3/Hands-on_Exercise_3.html#visualising-the-desire-lines",
    "href": "Hands-on_Ex_3/Hands-on_Exercise_3.html#visualising-the-desire-lines",
    "title": "Hands-on Exercise 2:Processing and Visualising Flow Data",
    "section": "6.3 Visualising the desire lines",
    "text": "6.3 Visualising the desire lines\nTo visualise the resulting desire lines, the code chunk below is used.\n\nlibrary(tmap)\n\ntm_shape(mpsz) +\n  tm_polygons() +\ntm_shape(flowLine) +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3) +\ntm_layout(legend.width = 0.5)  # 调整这个值以适合您的图例宽度需求\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length"
  },
  {
    "objectID": "Hands-on_Ex_3/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex_3/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "",
    "text": "performing geocoding using data downloaded from data.gov.sg\ncalibrating Geographically Weighted Poisson Regression"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#overview",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#overview",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "",
    "text": "performing geocoding using data downloaded from data.gov.sg\ncalibrating Geographically Weighted Poisson Regression"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#getting-started",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#getting-started",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Getting Started",
    "text": "Getting Started\n\npacman::p_load(tmap, sf, httr, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#geocoding-using-sla-api",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#geocoding-using-sla-api",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Geocoding using SLA API",
    "text": "Geocoding using SLA API\nGeocoding - process of aspatial description of a location e.g. address\n\nurl &lt;- \"https://www.onemap.gov.sg/api/common/elastic/search\"\n\ncsv &lt;- read_csv(\"data/aspatial/Generalinformationofschools.csv\")\npostcodes &lt;- csv$`postal_code`\n\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor(postcode in postcodes){\n  query&lt;-list('searchVal'=postcode,'returnGeom'='Y','getAddrDetails'='Y', 'pageNum'='1')\n  res &lt;- GET(url,query=query)\n  \n  if((content(res)$found)!=0){\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  } else{\n    not_found = data.frame(postcode)\n  }\n}\nmerged = merge(csv, found, by.x= 'postal_code', by.y = 'results.POSTAL', all=TRUE)\nwrite.csv(merged, file = \"data/aspatial/schools.csv\")\nwrite.csv(not_found, file = \"data/aspatial/not_found.csv\")\n\n\nImporting geospatial data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/In-Class_Ex_4/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\nImporting & tidying school data\n\nschools &lt;- read_csv(\"Data/Aspatial/Generalinformationofschools.csv\")\n\nRows: 346 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (31): school_name, url_address, address, postal_code, telephone_no, tele...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: Zhenghua Secondary School missing. Manually update latitude and longitude for ZHENGHUA SECONDARY SCHOOL\n\nLatitude: 1.389279\nLongitude: 103.7651\n\n\nurl &lt;- \"https://www.onemap.gov.sg/api/common/elastic/search\"\n\ncsv &lt;- read_csv(\"data/aspatial/Generalinformationofschools.csv\")\n\nRows: 346 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (31): school_name, url_address, address, postal_code, telephone_no, tele...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npostcodes &lt;- csv$`postal_code`\n\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor(postcode in postcodes){\n  query&lt;-list('searchVal'=postcode,'returnGeom'='Y','getAddrDetails'='Y', 'pageNum'='1')\n  res &lt;- GET(url,query=query)\n  \n  if((content(res)$found)!=0){\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  } else{\n    not_found = data.frame(postcode)\n  }\n}\nmerged = merge(csv, found, by.x= 'postal_code', by.y = 'results.POSTAL', all=TRUE)\nmerged1 &lt;- merged %&gt;%\n  mutate(\n    results.LATITUDE = ifelse(school_name == \"ZHENGHUA SECONDARY SCHOOL\", 1.389279, results.LATITUDE),\n    results.LONGITUDE = ifelse(school_name == \"ZHENGHUA SECONDARY SCHOOL\", 103.7651, results.LONGITUDE)\n  )\n\n\nschools &lt;- merged1 %&gt;%\n  rename(latitude = \"results.LATITUDE\", longitude = \"results.LONGITUDE\") %&gt;%\n  select(postal_code, school_name, latitude, longitude)\n\nNote: schools is a tibble dataframe object class\n\n\nConverting an aspatial data into a simple features tibble data.frame\n\nschools_sf &lt;- st_as_sf(schools,\n                       coords = c(\"longitude\", \"latitude\"),\n                       crs =4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\nPlotting a point simple feature layer\n\n#| code-fold: true\n#| code-sumary: \"Show the code\"\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(schools_sf) +\n  tm_dots() +\ntm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#preparing",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#preparing",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Preparing",
    "text": "Preparing\n\nmpsz$`SCHOOL_COUNT` &lt;- lengths(\n  st_intersects(\n    mpsz, schools_sf\n  )\n)\n\nSummary statistics\n\nsummary(mpsz$SCHOOL_COUNT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   0.000   1.054   2.000  12.000 \n\n\n\nretail_sf &lt;- st_read(dsn = \"data/geospatial\", layer = \"Retails\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `Retails' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/In-Class_Ex_4/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 37635 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4737.982 ymin: 25171.88 xmax: 48265.04 ymax: 50135.28\nProjected CRS: SVY21 / Singapore TM\n\n\n\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz) +\n  tm_polygons() +\ntm_shape(retail_sf) +\n  tm_dots()\n\nWarning: The shape mpsz is invalid. See sf::st_is_valid"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#data-integration-and-wrangling",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#data-integration-and-wrangling",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Data Integration and Wrangling",
    "text": "Data Integration and Wrangling\nImport the rds file into R environment\n\nflow_data &lt;- read_rds(\"data/rds/flow_data_tidy.rds\") \n\n\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,\n  0, flow_data$MORNING_PEAK)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,\n  0.000001, 1)\n\n\nflow_data &lt;- flow_data %&gt;%\n  filter(FlowNoIntra &gt; 0)\n\n\ninter_zonal_flow &lt;- flow_data %&gt;%\n  rename(TRIPS =MORNING_PEAK,\n         DIST = dist)"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#unconstrained-sim",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#unconstrained-sim",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Unconstrained SIM",
    "text": "Unconstrained SIM\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(SCHOOL_COUNT) + \n                log(RETAIL_COUNT) +\n                log(DIST),\n              family = poisson(link = \"log\"),\n              data = inter_zonal_flow,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(SCHOOL_COUNT) + log(RETAIL_COUNT) + \n    log(DIST), family = poisson(link = \"log\"), data = inter_zonal_flow, \n    na.action = na.exclude)\n\nCoefficients:\n      (Intercept)  log(SCHOOL_COUNT)  log(RETAIL_COUNT)          log(DIST)  \n          18.8651             0.7492             0.2050            -1.5751  \n\nDegrees of Freedom: 14470 Total (i.e. Null);  14467 Residual\nNull Deviance:      47090000 \nResidual Deviance: 25940000     AIC: 26030000\n\n\n\nGoodness-of-Fit\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1591336\n\n\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.448\n  adj. R2: 0.448"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#origin-constrained-sim",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#origin-constrained-sim",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Origin constrained SIM",
    "text": "Origin constrained SIM\n\norcSIM &lt;- glm(formula = TRIPS ~\n                ORIGIN_SZ +\n                log(SCHOOL_COUNT) +\n                log(RETAIL_COUNT) +\n                log(DIST) - 1,\n              family = poisson(link = \"log\"),\n              data = inter_zonal_flow,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(SCHOOL_COUNT) + log(RETAIL_COUNT) + \n    log(DIST) - 1, family = poisson(link = \"log\"), data = inter_zonal_flow, \n    na.action = na.exclude)\n\nCoefficients:\n                    Estimate Std. Error  z value Pr(&gt;|z|)    \nORIGIN_SZAMSZ01   19.8739840  0.0047627  4172.84   &lt;2e-16 ***\nORIGIN_SZAMSZ02   20.5902203  0.0042786  4812.33   &lt;2e-16 ***\nORIGIN_SZAMSZ03   20.2327026  0.0045531  4443.70   &lt;2e-16 ***\nORIGIN_SZAMSZ04   19.7744438  0.0049837  3967.79   &lt;2e-16 ***\nORIGIN_SZAMSZ05   19.6574529  0.0056396  3485.61   &lt;2e-16 ***\nORIGIN_SZAMSZ06   19.9659115  0.0048946  4079.16   &lt;2e-16 ***\nORIGIN_SZAMSZ07   18.6746164  0.0096316  1938.90   &lt;2e-16 ***\nORIGIN_SZAMSZ08   19.2701601  0.0090776  2122.82   &lt;2e-16 ***\nORIGIN_SZAMSZ09   19.9889467  0.0052858  3781.64   &lt;2e-16 ***\nORIGIN_SZAMSZ10   20.3422035  0.0045778  4443.62   &lt;2e-16 ***\nORIGIN_SZAMSZ11   18.3944113  0.0129212  1423.58   &lt;2e-16 ***\nORIGIN_SZAMSZ12   18.3484209  0.0109652  1673.33   &lt;2e-16 ***\nORIGIN_SZBDSZ01   20.9668587  0.0043388  4832.36   &lt;2e-16 ***\nORIGIN_SZBDSZ02   20.4059518  0.0050601  4032.75   &lt;2e-16 ***\nORIGIN_SZBDSZ03   20.6725514  0.0045276  4565.93   &lt;2e-16 ***\nORIGIN_SZBDSZ04   21.6703853  0.0038930  5566.44   &lt;2e-16 ***\nORIGIN_SZBDSZ05   20.7497445  0.0046085  4502.46   &lt;2e-16 ***\nORIGIN_SZBDSZ06   20.9119361  0.0046432  4503.77   &lt;2e-16 ***\nORIGIN_SZBDSZ07   18.9749815  0.0097896  1938.28   &lt;2e-16 ***\nORIGIN_SZBDSZ08   19.1933901  0.0091312  2101.95   &lt;2e-16 ***\nORIGIN_SZBKSZ01   19.5422606  0.0064732  3018.96   &lt;2e-16 ***\nORIGIN_SZBKSZ02   20.1748913  0.0050076  4028.89   &lt;2e-16 ***\nORIGIN_SZBKSZ03   20.3984624  0.0047226  4319.35   &lt;2e-16 ***\nORIGIN_SZBKSZ04   19.6182212  0.0059652  3288.76   &lt;2e-16 ***\nORIGIN_SZBKSZ05   19.6033818  0.0063181  3102.74   &lt;2e-16 ***\nORIGIN_SZBKSZ06   19.7145224  0.0056372  3497.20   &lt;2e-16 ***\nORIGIN_SZBKSZ07   20.4237448  0.0041912  4873.03   &lt;2e-16 ***\nORIGIN_SZBKSZ08   19.7992538  0.0050405  3928.02   &lt;2e-16 ***\nORIGIN_SZBKSZ09   19.7821586  0.0055558  3560.66   &lt;2e-16 ***\nORIGIN_SZBLSZ01   17.7977276  0.0149058  1194.01   &lt;2e-16 ***\nORIGIN_SZBLSZ02   17.4287491  0.0192364   906.03   &lt;2e-16 ***\nORIGIN_SZBLSZ03   16.5884288  0.0459848   360.74   &lt;2e-16 ***\nORIGIN_SZBLSZ04   17.7851626  0.0232823   763.89   &lt;2e-16 ***\nORIGIN_SZBMSZ01   20.0751840  0.0052887  3795.89   &lt;2e-16 ***\nORIGIN_SZBMSZ02   18.6956140  0.0066656  2804.80   &lt;2e-16 ***\nORIGIN_SZBMSZ03   19.3204425  0.0054755  3528.56   &lt;2e-16 ***\nORIGIN_SZBMSZ04   19.4724220  0.0049390  3942.59   &lt;2e-16 ***\nORIGIN_SZBMSZ05   16.9581801  0.0168804  1004.61   &lt;2e-16 ***\nORIGIN_SZBMSZ06   16.9898638  0.0181852   934.27   &lt;2e-16 ***\nORIGIN_SZBMSZ07   19.2868403  0.0056231  3429.91   &lt;2e-16 ***\nORIGIN_SZBMSZ08   19.1477543  0.0055918  3424.28   &lt;2e-16 ***\nORIGIN_SZBMSZ09   18.7564539  0.0086298  2173.46   &lt;2e-16 ***\nORIGIN_SZBMSZ10   18.3617854  0.0089250  2057.35   &lt;2e-16 ***\nORIGIN_SZBMSZ11   18.9167941  0.0063340  2986.54   &lt;2e-16 ***\nORIGIN_SZBMSZ12   18.7874661  0.0093024  2019.63   &lt;2e-16 ***\nORIGIN_SZBMSZ13   19.5654046  0.0057517  3401.70   &lt;2e-16 ***\nORIGIN_SZBMSZ14   19.0685619  0.0063346  3010.24   &lt;2e-16 ***\nORIGIN_SZBMSZ15   19.4403124  0.0058147  3343.30   &lt;2e-16 ***\nORIGIN_SZBMSZ16   18.4469203  0.0092638  1991.28   &lt;2e-16 ***\nORIGIN_SZBMSZ17   18.3430175  0.0157692  1163.22   &lt;2e-16 ***\nORIGIN_SZBPSZ01   20.1806714  0.0053660  3760.81   &lt;2e-16 ***\nORIGIN_SZBPSZ02   19.8116707  0.0061485  3222.19   &lt;2e-16 ***\nORIGIN_SZBPSZ03   19.8467602  0.0059769  3320.57   &lt;2e-16 ***\nORIGIN_SZBPSZ04   20.4613200  0.0048398  4227.72   &lt;2e-16 ***\nORIGIN_SZBPSZ05   20.5379711  0.0043769  4692.39   &lt;2e-16 ***\nORIGIN_SZBPSZ06   18.8948034  0.0093668  2017.21   &lt;2e-16 ***\nORIGIN_SZBPSZ07   19.4104568  0.0087961  2206.70   &lt;2e-16 ***\nORIGIN_SZBSSZ01   20.0139503  0.0056561  3538.45   &lt;2e-16 ***\nORIGIN_SZBSSZ02   20.2543885  0.0047198  4291.38   &lt;2e-16 ***\nORIGIN_SZBSSZ03   19.5428803  0.0052713  3707.41   &lt;2e-16 ***\nORIGIN_SZBTSZ01   20.0198045  0.0058541  3419.77   &lt;2e-16 ***\nORIGIN_SZBTSZ02   19.3618525  0.0081472  2376.51   &lt;2e-16 ***\nORIGIN_SZBTSZ03   19.5883853  0.0068935  2841.59   &lt;2e-16 ***\nORIGIN_SZBTSZ04   18.7720238  0.0103909  1806.58   &lt;2e-16 ***\nORIGIN_SZBTSZ05   18.8069026  0.0120628  1559.08   &lt;2e-16 ***\nORIGIN_SZBTSZ06   18.7068633  0.0094575  1978.00   &lt;2e-16 ***\nORIGIN_SZBTSZ07   17.6292257  0.0141551  1245.43   &lt;2e-16 ***\nORIGIN_SZBTSZ08   18.6989374  0.0109610  1705.94   &lt;2e-16 ***\nORIGIN_SZCBSZ01   18.2189868  0.0548317   332.27   &lt;2e-16 ***\nORIGIN_SZCCSZ01   18.9734563  0.0139450  1360.59   &lt;2e-16 ***\nORIGIN_SZCHSZ01   19.5955119  0.0121035  1619.00   &lt;2e-16 ***\nORIGIN_SZCHSZ02   19.3320960  0.0081620  2368.55   &lt;2e-16 ***\nORIGIN_SZCHSZ03   21.2164518  0.0063552  3338.43   &lt;2e-16 ***\nORIGIN_SZCKSZ01   20.1046845  0.0049333  4075.29   &lt;2e-16 ***\nORIGIN_SZCKSZ02   20.5371946  0.0050256  4086.53   &lt;2e-16 ***\nORIGIN_SZCKSZ03   20.7210560  0.0042184  4912.07   &lt;2e-16 ***\nORIGIN_SZCKSZ04   21.4013886  0.0042524  5032.80   &lt;2e-16 ***\nORIGIN_SZCKSZ05   20.9413146  0.0049434  4236.18   &lt;2e-16 ***\nORIGIN_SZCKSZ06   20.2557727  0.0071832  2819.88   &lt;2e-16 ***\nORIGIN_SZCLSZ01   19.3383703  0.0076634  2523.46   &lt;2e-16 ***\nORIGIN_SZCLSZ02   18.5226956  0.0135522  1366.77   &lt;2e-16 ***\nORIGIN_SZCLSZ03   19.0225512  0.0080145  2373.51   &lt;2e-16 ***\nORIGIN_SZCLSZ04   20.7981505  0.0042400  4905.22   &lt;2e-16 ***\nORIGIN_SZCLSZ05   18.3015625  0.0146815  1246.58   &lt;2e-16 ***\nORIGIN_SZCLSZ06   20.8207386  0.0039567  5262.09   &lt;2e-16 ***\nORIGIN_SZCLSZ07   19.6728958  0.0054199  3629.76   &lt;2e-16 ***\nORIGIN_SZCLSZ08   20.0851929  0.0056956  3526.43   &lt;2e-16 ***\nORIGIN_SZCLSZ09   18.5749589  0.0165415  1122.93   &lt;2e-16 ***\nORIGIN_SZDTSZ02   15.8276209  0.0833992   189.78   &lt;2e-16 ***\nORIGIN_SZDTSZ03   16.2512838  0.0737972   220.22   &lt;2e-16 ***\nORIGIN_SZDTSZ13   16.7744385  0.0312450   536.87   &lt;2e-16 ***\nORIGIN_SZGLSZ01   18.2368248  0.0096104  1897.62   &lt;2e-16 ***\nORIGIN_SZGLSZ02   19.8705255  0.0049014  4054.06   &lt;2e-16 ***\nORIGIN_SZGLSZ03   19.8249435  0.0053109  3732.85   &lt;2e-16 ***\nORIGIN_SZGLSZ04   20.7800335  0.0041261  5036.20   &lt;2e-16 ***\nORIGIN_SZGLSZ05   20.6040494  0.0043049  4786.23   &lt;2e-16 ***\nORIGIN_SZHGSZ01   20.0273475  0.0044824  4468.04   &lt;2e-16 ***\nORIGIN_SZHGSZ02   20.2480656  0.0044575  4542.47   &lt;2e-16 ***\nORIGIN_SZHGSZ03   20.0756442  0.0049003  4096.81   &lt;2e-16 ***\nORIGIN_SZHGSZ04   20.7577748  0.0040465  5129.84   &lt;2e-16 ***\nORIGIN_SZHGSZ05   20.9779992  0.0040123  5228.42   &lt;2e-16 ***\nORIGIN_SZHGSZ06   19.7403058  0.0054229  3640.20   &lt;2e-16 ***\nORIGIN_SZHGSZ07   20.1896268  0.0046051  4384.22   &lt;2e-16 ***\nORIGIN_SZHGSZ08   19.8646492  0.0052403  3790.72   &lt;2e-16 ***\nORIGIN_SZHGSZ09   18.3647736  0.0069196  2654.04   &lt;2e-16 ***\nORIGIN_SZHGSZ10   16.8720475  0.0421046   400.72   &lt;2e-16 ***\nORIGIN_SZJESZ01   20.2673794  0.0046723  4337.79   &lt;2e-16 ***\nORIGIN_SZJESZ02   20.0595982  0.0046503  4313.61   &lt;2e-16 ***\nORIGIN_SZJESZ03   19.9128778  0.0049848  3994.75   &lt;2e-16 ***\nORIGIN_SZJESZ04   18.5053667  0.0099227  1864.94   &lt;2e-16 ***\nORIGIN_SZJESZ05   17.8172930  0.0138840  1283.29   &lt;2e-16 ***\nORIGIN_SZJESZ06   20.0124157  0.0045009  4446.36   &lt;2e-16 ***\nORIGIN_SZJESZ07   18.1821423  0.0117267  1550.49   &lt;2e-16 ***\nORIGIN_SZJESZ08   18.8713046  0.0116456  1620.46   &lt;2e-16 ***\nORIGIN_SZJESZ09   20.5535527  0.0048456  4241.72   &lt;2e-16 ***\nORIGIN_SZJESZ10   18.4922322  0.0191243   966.95   &lt;2e-16 ***\nORIGIN_SZJESZ11   18.2891211  0.0197114   927.85   &lt;2e-16 ***\nORIGIN_SZJWSZ01   20.4912737  0.0063102  3247.35   &lt;2e-16 ***\nORIGIN_SZJWSZ02   20.8236694  0.0042249  4928.82   &lt;2e-16 ***\nORIGIN_SZJWSZ03   21.2587613  0.0039733  5350.40   &lt;2e-16 ***\nORIGIN_SZJWSZ04   20.3816464  0.0046199  4411.67   &lt;2e-16 ***\nORIGIN_SZJWSZ05   18.0607448  0.0128857  1401.61   &lt;2e-16 ***\nORIGIN_SZJWSZ06   18.7015202  0.0107614  1737.83   &lt;2e-16 ***\nORIGIN_SZJWSZ07   17.3991822  0.0277096   627.91   &lt;2e-16 ***\nORIGIN_SZJWSZ08   21.8044465  0.0037356  5836.95   &lt;2e-16 ***\nORIGIN_SZJWSZ09   21.5414930  0.0036033  5978.19   &lt;2e-16 ***\nORIGIN_SZKLSZ01   20.0307712  0.0047868  4184.59   &lt;2e-16 ***\nORIGIN_SZKLSZ02   19.0634769  0.0062318  3059.05   &lt;2e-16 ***\nORIGIN_SZKLSZ03   19.2685700  0.0057172  3370.25   &lt;2e-16 ***\nORIGIN_SZKLSZ04   17.7085067  0.0119809  1478.06   &lt;2e-16 ***\nORIGIN_SZKLSZ05   18.6384471  0.0107596  1732.26   &lt;2e-16 ***\nORIGIN_SZKLSZ06   13.7280296  0.1857160    73.92   &lt;2e-16 ***\nORIGIN_SZKLSZ07   18.6425146  0.0084952  2194.47   &lt;2e-16 ***\nORIGIN_SZKLSZ08   18.0928506  0.0101567  1781.37   &lt;2e-16 ***\nORIGIN_SZLKSZ01   17.8907138  0.0397083   450.55   &lt;2e-16 ***\nORIGIN_SZMDSZ01   18.7605188  0.0285455   657.22   &lt;2e-16 ***\nORIGIN_SZMDSZ02   19.1533927  0.0102815  1862.90   &lt;2e-16 ***\nORIGIN_SZMDSZ03   17.8404982  0.0169690  1051.36   &lt;2e-16 ***\nORIGIN_SZMPSZ01   19.0765941  0.0083937  2272.74   &lt;2e-16 ***\nORIGIN_SZMPSZ02   19.2162527  0.0068331  2812.24   &lt;2e-16 ***\nORIGIN_SZMPSZ03   19.9965344  0.0054569  3664.44   &lt;2e-16 ***\nORIGIN_SZMUSZ02   15.9130765  0.1037472   153.38   &lt;2e-16 ***\nORIGIN_SZNTSZ01   17.0840999  0.0352513   484.64   &lt;2e-16 ***\nORIGIN_SZNTSZ02   16.5792122  0.0233186   710.99   &lt;2e-16 ***\nORIGIN_SZNTSZ03   18.9506415  0.0075957  2494.93   &lt;2e-16 ***\nORIGIN_SZNTSZ05   15.8770261  0.0495825   320.21   &lt;2e-16 ***\nORIGIN_SZNTSZ06   15.3997415  0.0557029   276.46   &lt;2e-16 ***\nORIGIN_SZNVSZ01   20.2241694  0.0043487  4650.65   &lt;2e-16 ***\nORIGIN_SZNVSZ02   19.1897826  0.0065383  2934.97   &lt;2e-16 ***\nORIGIN_SZNVSZ03   18.8854268  0.0080459  2347.22   &lt;2e-16 ***\nORIGIN_SZNVSZ04   18.8940191  0.0090985  2076.61   &lt;2e-16 ***\nORIGIN_SZNVSZ05   17.6278585  0.0168107  1048.61   &lt;2e-16 ***\nORIGIN_SZPGSZ01   19.4825220  0.0122960  1584.46   &lt;2e-16 ***\nORIGIN_SZPGSZ02   19.4726761  0.0073116  2663.25   &lt;2e-16 ***\nORIGIN_SZPGSZ03   20.5515713  0.0045631  4503.86   &lt;2e-16 ***\nORIGIN_SZPGSZ04   21.0527131  0.0041500  5072.89   &lt;2e-16 ***\nORIGIN_SZPGSZ05   20.1436604  0.0057267  3517.48   &lt;2e-16 ***\nORIGIN_SZPLSZ01   19.1832002  0.0120006  1598.53   &lt;2e-16 ***\nORIGIN_SZPLSZ02   18.8752206  0.0149740  1260.53   &lt;2e-16 ***\nORIGIN_SZPLSZ03   18.1000818  0.0371769   486.86   &lt;2e-16 ***\nORIGIN_SZPLSZ04   17.1730559  0.0370280   463.79   &lt;2e-16 ***\nORIGIN_SZPLSZ05   17.9084439  0.0225031   795.82   &lt;2e-16 ***\nORIGIN_SZPNSZ01   21.0804425  0.0044829  4702.41   &lt;2e-16 ***\nORIGIN_SZPNSZ02   19.8822123  0.0111507  1783.05   &lt;2e-16 ***\nORIGIN_SZPNSZ03   17.9293289  0.0193571   926.24   &lt;2e-16 ***\nORIGIN_SZPNSZ04   17.1039594  0.0334954   510.64   &lt;2e-16 ***\nORIGIN_SZPNSZ05   18.2543864  0.0275554   662.46   &lt;2e-16 ***\nORIGIN_SZPRSZ01   19.8777935  0.0117586  1690.49   &lt;2e-16 ***\nORIGIN_SZPRSZ02   21.0751780  0.0044832  4700.88   &lt;2e-16 ***\nORIGIN_SZPRSZ03   20.6717019  0.0045577  4535.55   &lt;2e-16 ***\nORIGIN_SZPRSZ04   19.6365125  0.0074923  2620.90   &lt;2e-16 ***\nORIGIN_SZPRSZ05   21.3132151  0.0042119  5060.24   &lt;2e-16 ***\nORIGIN_SZPRSZ06   18.9314574  0.0117278  1614.24   &lt;2e-16 ***\nORIGIN_SZPRSZ07   17.2822918  0.0162430  1063.98   &lt;2e-16 ***\nORIGIN_SZPRSZ08   19.9267642  0.0062298  3198.62   &lt;2e-16 ***\nORIGIN_SZQTSZ01   19.7357175  0.0066359  2974.08   &lt;2e-16 ***\nORIGIN_SZQTSZ02   19.2082141  0.0061402  3128.26   &lt;2e-16 ***\nORIGIN_SZQTSZ03   19.7771883  0.0056220  3517.83   &lt;2e-16 ***\nORIGIN_SZQTSZ04   18.7114421  0.0072842  2568.76   &lt;2e-16 ***\nORIGIN_SZQTSZ05   19.3049324  0.0062401  3093.69   &lt;2e-16 ***\nORIGIN_SZQTSZ06   19.2643228  0.0065590  2937.09   &lt;2e-16 ***\nORIGIN_SZQTSZ07   18.5697347  0.0095373  1947.06   &lt;2e-16 ***\nORIGIN_SZQTSZ08   19.6147001  0.0061330  3198.21   &lt;2e-16 ***\nORIGIN_SZQTSZ09   19.2550793  0.0069947  2752.82   &lt;2e-16 ***\nORIGIN_SZQTSZ10   19.5801866  0.0064513  3035.07   &lt;2e-16 ***\nORIGIN_SZQTSZ11   17.7398366  0.0143648  1234.95   &lt;2e-16 ***\nORIGIN_SZQTSZ12   17.2420354  0.0186736   923.34   &lt;2e-16 ***\nORIGIN_SZQTSZ13   19.3857418  0.0078878  2457.69   &lt;2e-16 ***\nORIGIN_SZQTSZ14   18.1300753  0.0122096  1484.90   &lt;2e-16 ***\nORIGIN_SZQTSZ15   19.4222283  0.0120871  1606.86   &lt;2e-16 ***\nORIGIN_SZRCSZ01   18.1549045  0.0125108  1451.13   &lt;2e-16 ***\nORIGIN_SZRCSZ06   18.8836400  0.0082161  2298.38   &lt;2e-16 ***\nORIGIN_SZRVSZ01   16.7864438  0.0323796   518.43   &lt;2e-16 ***\nORIGIN_SZRVSZ02   16.4203244  0.0276836   593.14   &lt;2e-16 ***\nORIGIN_SZRVSZ03   16.6453738  0.0244992   679.42   &lt;2e-16 ***\nORIGIN_SZRVSZ04   15.9559213  0.0556344   286.80   &lt;2e-16 ***\nORIGIN_SZRVSZ05   17.0476331  0.0164122  1038.71   &lt;2e-16 ***\nORIGIN_SZSBSZ01   20.0417968  0.0062488  3207.29   &lt;2e-16 ***\nORIGIN_SZSBSZ02   19.1869565  0.0081051  2367.26   &lt;2e-16 ***\nORIGIN_SZSBSZ03   20.5769861  0.0045108  4561.70   &lt;2e-16 ***\nORIGIN_SZSBSZ04   20.5154199  0.0050548  4058.57   &lt;2e-16 ***\nORIGIN_SZSBSZ05   19.6250669  0.0065562  2993.35   &lt;2e-16 ***\nORIGIN_SZSBSZ06   18.8419757  0.0171135  1101.00   &lt;2e-16 ***\nORIGIN_SZSBSZ07   19.4897259  0.0124528  1565.09   &lt;2e-16 ***\nORIGIN_SZSBSZ08   18.7027917  0.0140545  1330.73   &lt;2e-16 ***\nORIGIN_SZSBSZ09   18.8893480  0.0088571  2132.67   &lt;2e-16 ***\nORIGIN_SZSESZ02   20.8962192  0.0041665  5015.34   &lt;2e-16 ***\nORIGIN_SZSESZ03   20.9452771  0.0039737  5270.94   &lt;2e-16 ***\nORIGIN_SZSESZ04   20.6576142  0.0046364  4455.55   &lt;2e-16 ***\nORIGIN_SZSESZ05   19.5170732  0.0058912  3312.92   &lt;2e-16 ***\nORIGIN_SZSESZ06   20.7595824  0.0045747  4537.89   &lt;2e-16 ***\nORIGIN_SZSESZ07   17.6888256  0.0195787   903.47   &lt;2e-16 ***\nORIGIN_SZSGSZ01   19.1359250  0.0085781  2230.79   &lt;2e-16 ***\nORIGIN_SZSGSZ02   18.5614369  0.0102037  1819.10   &lt;2e-16 ***\nORIGIN_SZSGSZ03   19.9933176  0.0050434  3964.23   &lt;2e-16 ***\nORIGIN_SZSGSZ04   20.2426871  0.0047211  4287.71   &lt;2e-16 ***\nORIGIN_SZSGSZ05   18.0114965  0.0107743  1671.70   &lt;2e-16 ***\nORIGIN_SZSGSZ06   20.2593194  0.0044538  4548.76   &lt;2e-16 ***\nORIGIN_SZSGSZ07   19.0763664  0.0062968  3029.54   &lt;2e-16 ***\nORIGIN_SZSKSZ01   19.9222451  0.0085136  2340.04   &lt;2e-16 ***\nORIGIN_SZSKSZ02   20.8633383  0.0055248  3776.33   &lt;2e-16 ***\nORIGIN_SZSKSZ03   19.6528148  0.0080534  2440.33   &lt;2e-16 ***\nORIGIN_SZSKSZ04   18.0754470  0.0275771   655.45   &lt;2e-16 ***\nORIGIN_SZSKSZ05   19.1192521  0.0155579  1228.91   &lt;2e-16 ***\nORIGIN_SZSLSZ01   17.1501034  0.0329384   520.67   &lt;2e-16 ***\nORIGIN_SZSLSZ04   19.5949774  0.0076753  2552.98   &lt;2e-16 ***\nORIGIN_SZSRSZ01   16.9761403  0.0162020  1047.78   &lt;2e-16 ***\nORIGIN_SZTHSZ01   17.9695687  0.0488559   367.81   &lt;2e-16 ***\nORIGIN_SZTHSZ03   18.5427522  0.0223617   829.22   &lt;2e-16 ***\nORIGIN_SZTHSZ04   17.4760374  0.0286247   610.52   &lt;2e-16 ***\nORIGIN_SZTHSZ06   17.8401186  0.0183322   973.16   &lt;2e-16 ***\nORIGIN_SZTMSZ01   20.3406361  0.0056607  3593.33   &lt;2e-16 ***\nORIGIN_SZTMSZ02   22.0307026  0.0037386  5892.85   &lt;2e-16 ***\nORIGIN_SZTMSZ03   21.3451920  0.0040606  5256.65   &lt;2e-16 ***\nORIGIN_SZTMSZ04   20.6611593  0.0049896  4140.87   &lt;2e-16 ***\nORIGIN_SZTMSZ05   19.3323133  0.0112868  1712.82   &lt;2e-16 ***\nORIGIN_SZTNSZ01   17.9513571  0.0128266  1399.54   &lt;2e-16 ***\nORIGIN_SZTNSZ02   18.0267387  0.0098372  1832.51   &lt;2e-16 ***\nORIGIN_SZTNSZ03   17.7253700  0.0134668  1316.23   &lt;2e-16 ***\nORIGIN_SZTNSZ04   19.4474075  0.0073760  2636.59   &lt;2e-16 ***\nORIGIN_SZTPSZ01   19.1078631  0.0065635  2911.25   &lt;2e-16 ***\nORIGIN_SZTPSZ02   20.2837634  0.0041411  4898.18   &lt;2e-16 ***\nORIGIN_SZTPSZ03   19.1838238  0.0059552  3221.37   &lt;2e-16 ***\nORIGIN_SZTPSZ04   19.1805388  0.0054778  3501.53   &lt;2e-16 ***\nORIGIN_SZTPSZ05   19.3718076  0.0058610  3305.18   &lt;2e-16 ***\nORIGIN_SZTPSZ06   19.6605723  0.0054968  3576.70   &lt;2e-16 ***\nORIGIN_SZTPSZ07   19.4499807  0.0060491  3215.36   &lt;2e-16 ***\nORIGIN_SZTPSZ08   18.7996538  0.0095757  1963.28   &lt;2e-16 ***\nORIGIN_SZTPSZ09   19.0025110  0.0067068  2833.31   &lt;2e-16 ***\nORIGIN_SZTPSZ10   18.8899657  0.0076094  2482.46   &lt;2e-16 ***\nORIGIN_SZTPSZ11   19.6277780  0.0053983  3635.93   &lt;2e-16 ***\nORIGIN_SZTPSZ12   19.1471104  0.0065742  2912.45   &lt;2e-16 ***\nORIGIN_SZTSSZ01   17.4901113  0.0478954   365.17   &lt;2e-16 ***\nORIGIN_SZTSSZ02   20.4997466  0.0081850  2504.55   &lt;2e-16 ***\nORIGIN_SZTSSZ03   20.1076553  0.0084728  2373.19   &lt;2e-16 ***\nORIGIN_SZTSSZ04   20.0646610  0.0089008  2254.26   &lt;2e-16 ***\nORIGIN_SZTSSZ05   19.3962067  0.0151392  1281.19   &lt;2e-16 ***\nORIGIN_SZTSSZ06   20.9235857  0.0178278  1173.65   &lt;2e-16 ***\nORIGIN_SZWCSZ01   20.8411600  0.0086519  2408.86   &lt;2e-16 ***\nORIGIN_SZWCSZ02   17.7355404  0.0328889   539.26   &lt;2e-16 ***\nORIGIN_SZWCSZ03   14.9380886  0.1240699   120.40   &lt;2e-16 ***\nORIGIN_SZWDSZ01   21.1969012  0.0037830  5603.23   &lt;2e-16 ***\nORIGIN_SZWDSZ02   20.5930001  0.0044572  4620.13   &lt;2e-16 ***\nORIGIN_SZWDSZ03   21.2521867  0.0041672  5099.85   &lt;2e-16 ***\nORIGIN_SZWDSZ04   21.0702687  0.0048648  4331.13   &lt;2e-16 ***\nORIGIN_SZWDSZ05   20.4008998  0.0051801  3938.35   &lt;2e-16 ***\nORIGIN_SZWDSZ06   20.6669176  0.0049280  4193.78   &lt;2e-16 ***\nORIGIN_SZWDSZ07   19.0500370  0.0082729  2302.71   &lt;2e-16 ***\nORIGIN_SZWDSZ08   19.0816252  0.0080667  2365.49   &lt;2e-16 ***\nORIGIN_SZWDSZ09   21.4182096  0.0040391  5302.73   &lt;2e-16 ***\nORIGIN_SZYSSZ01   19.5355157  0.0057540  3395.14   &lt;2e-16 ***\nORIGIN_SZYSSZ02   20.8737972  0.0048278  4323.64   &lt;2e-16 ***\nORIGIN_SZYSSZ03   21.6614437  0.0040011  5413.81   &lt;2e-16 ***\nORIGIN_SZYSSZ04   20.9305289  0.0043595  4801.10   &lt;2e-16 ***\nORIGIN_SZYSSZ05   20.1727678  0.0058466  3450.34   &lt;2e-16 ***\nORIGIN_SZYSSZ06   19.1481507  0.0116724  1640.47   &lt;2e-16 ***\nORIGIN_SZYSSZ07   18.7919074  0.0141636  1326.78   &lt;2e-16 ***\nORIGIN_SZYSSZ08   19.9733515  0.0061229  3262.07   &lt;2e-16 ***\nORIGIN_SZYSSZ09   20.9366181  0.0040347  5189.15   &lt;2e-16 ***\nlog(SCHOOL_COUNT)  0.4755516  0.0004701  1011.55   &lt;2e-16 ***\nlog(RETAIL_COUNT)  0.1796905  0.0001856   968.12   &lt;2e-16 ***\nlog(DIST)         -1.6929522  0.0004093 -4136.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 189463537  on 14471  degrees of freedom\nResidual deviance:  15526121  on 14189  degrees of freedom\nAIC: 15615824\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nGoodness-of-Fit\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4362208"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#destination-constrained",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#destination-constrained",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Destination Constrained",
    "text": "Destination Constrained\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(SCHOOL_COUNT) + \n                log(DIST),\n              family = poisson(link = \"log\"),\n              data = inter_zonal_flow,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(SCHOOL_COUNT) + log(DIST), \n    family = poisson(link = \"log\"), data = inter_zonal_flow, \n    na.action = na.exclude)\n\nCoefficients: (1 not defined because of singularities)\n                    Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)       21.1707732  0.0043061  4916.502  &lt; 2e-16 ***\nDESTIN_SZAMSZ02    0.0371012  0.0044770     8.287  &lt; 2e-16 ***\nDESTIN_SZAMSZ03    0.1305469  0.0043909    29.731  &lt; 2e-16 ***\nDESTIN_SZAMSZ04   -1.0399621  0.0063788  -163.035  &lt; 2e-16 ***\nDESTIN_SZAMSZ05   -1.1200854  0.0064528  -173.581  &lt; 2e-16 ***\nDESTIN_SZAMSZ06   -1.1256714  0.0064401  -174.790  &lt; 2e-16 ***\nDESTIN_SZAMSZ07   -1.5880948  0.0097145  -163.477  &lt; 2e-16 ***\nDESTIN_SZAMSZ08   -0.5970367  0.0068843   -86.724  &lt; 2e-16 ***\nDESTIN_SZAMSZ09   -1.0674296  0.0065644  -162.608  &lt; 2e-16 ***\nDESTIN_SZAMSZ10   -0.0612203  0.0045919   -13.332  &lt; 2e-16 ***\nDESTIN_SZAMSZ11   -0.6955269  0.0086700   -80.222  &lt; 2e-16 ***\nDESTIN_SZAMSZ12    0.1620088  0.0050181    32.285  &lt; 2e-16 ***\nDESTIN_SZBDSZ01    0.9892232  0.0039751   248.856  &lt; 2e-16 ***\nDESTIN_SZBDSZ02    0.4017891  0.0052374    76.715  &lt; 2e-16 ***\nDESTIN_SZBDSZ03    0.3915377  0.0047764    81.974  &lt; 2e-16 ***\nDESTIN_SZBDSZ04    1.3768947  0.0038180   360.637  &lt; 2e-16 ***\nDESTIN_SZBDSZ05    0.9453454  0.0040922   231.014  &lt; 2e-16 ***\nDESTIN_SZBDSZ06    0.6929711  0.0046554   148.852  &lt; 2e-16 ***\nDESTIN_SZBDSZ07   -0.3688620  0.0096224   -38.333  &lt; 2e-16 ***\nDESTIN_SZBDSZ08   -0.9924523  0.0109418   -90.703  &lt; 2e-16 ***\nDESTIN_SZBKSZ01   -1.0093826  0.0067519  -149.497  &lt; 2e-16 ***\nDESTIN_SZBKSZ02   -0.1646950  0.0056050   -29.384  &lt; 2e-16 ***\nDESTIN_SZBKSZ03   -0.7702454  0.0060023  -128.324  &lt; 2e-16 ***\nDESTIN_SZBKSZ04   -0.2128866  0.0050053   -42.532  &lt; 2e-16 ***\nDESTIN_SZBKSZ05   -0.9222879  0.0066223  -139.271  &lt; 2e-16 ***\nDESTIN_SZBKSZ06   -1.0097287  0.0062224  -162.274  &lt; 2e-16 ***\nDESTIN_SZBKSZ07    0.0518689  0.0042400    12.233  &lt; 2e-16 ***\nDESTIN_SZBKSZ08   -1.2300650  0.0070344  -174.863  &lt; 2e-16 ***\nDESTIN_SZBKSZ09   -0.2258130  0.0049947   -45.211  &lt; 2e-16 ***\nDESTIN_SZBLSZ01   -0.8157866  0.0070499  -115.715  &lt; 2e-16 ***\nDESTIN_SZBLSZ02   -0.3027143  0.0065218   -46.416  &lt; 2e-16 ***\nDESTIN_SZBLSZ03    0.7958391  0.0074056   107.464  &lt; 2e-16 ***\nDESTIN_SZBLSZ04   -1.1098772  0.0131963   -84.105  &lt; 2e-16 ***\nDESTIN_SZBMSZ01   -0.1310007  0.0049367   -26.536  &lt; 2e-16 ***\nDESTIN_SZBMSZ02   -0.9571354  0.0049558  -193.135  &lt; 2e-16 ***\nDESTIN_SZBMSZ03   -1.2732655  0.0057277  -222.302  &lt; 2e-16 ***\nDESTIN_SZBMSZ04   -1.2035188  0.0051428  -234.019  &lt; 2e-16 ***\nDESTIN_SZBMSZ05   -1.1303172  0.0069498  -162.640  &lt; 2e-16 ***\nDESTIN_SZBMSZ06   -2.2950071  0.0131523  -174.495  &lt; 2e-16 ***\nDESTIN_SZBMSZ07   -0.3931446  0.0046619   -84.331  &lt; 2e-16 ***\nDESTIN_SZBMSZ08   -1.8285333  0.0065026  -281.200  &lt; 2e-16 ***\nDESTIN_SZBMSZ09   -3.3025704  0.0152460  -216.619  &lt; 2e-16 ***\nDESTIN_SZBMSZ10   -2.4668974  0.0089386  -275.984  &lt; 2e-16 ***\nDESTIN_SZBMSZ11   -2.1775261  0.0080886  -269.211  &lt; 2e-16 ***\nDESTIN_SZBMSZ12   -1.5533488  0.0080036  -194.082  &lt; 2e-16 ***\nDESTIN_SZBMSZ13   -0.6992349  0.0053943  -129.625  &lt; 2e-16 ***\nDESTIN_SZBMSZ14   -1.8682939  0.0077676  -240.524  &lt; 2e-16 ***\nDESTIN_SZBMSZ15   -1.6438723  0.0071068  -231.308  &lt; 2e-16 ***\nDESTIN_SZBMSZ16   -2.5319233  0.0113895  -222.304  &lt; 2e-16 ***\nDESTIN_SZBMSZ17   -2.3908644  0.0165777  -144.222  &lt; 2e-16 ***\nDESTIN_SZBPSZ01   -0.6933581  0.0056465  -122.794  &lt; 2e-16 ***\nDESTIN_SZBPSZ02   -1.5690150  0.0084981  -184.630  &lt; 2e-16 ***\nDESTIN_SZBPSZ03   -1.2386463  0.0081265  -152.421  &lt; 2e-16 ***\nDESTIN_SZBPSZ04   -0.4837251  0.0059697   -81.030  &lt; 2e-16 ***\nDESTIN_SZBPSZ05    0.4454953  0.0040664   109.555  &lt; 2e-16 ***\nDESTIN_SZBPSZ06   -0.6899975  0.0078508   -87.889  &lt; 2e-16 ***\nDESTIN_SZBPSZ07   -0.0337850  0.0080286    -4.208 2.58e-05 ***\nDESTIN_SZBSSZ01    0.0103408  0.0049750     2.079  0.03766 *  \nDESTIN_SZBSSZ02   -0.6528407  0.0056160  -116.247  &lt; 2e-16 ***\nDESTIN_SZBSSZ03    0.1882120  0.0041566    45.280  &lt; 2e-16 ***\nDESTIN_SZBTSZ01    0.3382397  0.0043637    77.513  &lt; 2e-16 ***\nDESTIN_SZBTSZ02   -0.1875880  0.0068276   -27.475  &lt; 2e-16 ***\nDESTIN_SZBTSZ03   -0.0023969  0.0054551    -0.439  0.66038    \nDESTIN_SZBTSZ04   -1.4111336  0.0108345  -130.244  &lt; 2e-16 ***\nDESTIN_SZBTSZ05   -0.3020060  0.0069383   -43.528  &lt; 2e-16 ***\nDESTIN_SZBTSZ06   -0.9069295  0.0071064  -127.621  &lt; 2e-16 ***\nDESTIN_SZBTSZ07   -2.0566033  0.0110692  -185.795  &lt; 2e-16 ***\nDESTIN_SZBTSZ08   -1.6308254  0.0100369  -162.484  &lt; 2e-16 ***\nDESTIN_SZCBSZ01   -4.6894221  0.3162421   -14.829  &lt; 2e-16 ***\nDESTIN_SZCCSZ01   -0.3175428  0.0081545   -38.941  &lt; 2e-16 ***\nDESTIN_SZCHSZ01   -0.2225262  0.0097164   -22.902  &lt; 2e-16 ***\nDESTIN_SZCHSZ02   -0.0527951  0.0053337    -9.898  &lt; 2e-16 ***\nDESTIN_SZCHSZ03    2.5791911  0.0040210   641.427  &lt; 2e-16 ***\nDESTIN_SZCKSZ01    0.0380461  0.0049002     7.764 8.22e-15 ***\nDESTIN_SZCKSZ02   -0.5355692  0.0056427   -94.913  &lt; 2e-16 ***\nDESTIN_SZCKSZ03    0.7279591  0.0039202   185.692  &lt; 2e-16 ***\nDESTIN_SZCKSZ04   -0.3927873  0.0064849   -60.569  &lt; 2e-16 ***\nDESTIN_SZCKSZ05   -0.2265622  0.0067908   -33.363  &lt; 2e-16 ***\nDESTIN_SZCKSZ06    0.3792036  0.0063560    59.661  &lt; 2e-16 ***\nDESTIN_SZCLSZ01    0.1985789  0.0047824    41.523  &lt; 2e-16 ***\nDESTIN_SZCLSZ02   -2.2113621  0.0133556  -165.576  &lt; 2e-16 ***\nDESTIN_SZCLSZ03   -0.9255834  0.0079113  -116.995  &lt; 2e-16 ***\nDESTIN_SZCLSZ04   -0.1778523  0.0047148   -37.722  &lt; 2e-16 ***\nDESTIN_SZCLSZ05   -1.0165236  0.0084225  -120.692  &lt; 2e-16 ***\nDESTIN_SZCLSZ06    0.0782223  0.0042366    18.464  &lt; 2e-16 ***\nDESTIN_SZCLSZ07   -0.6287187  0.0054055  -116.311  &lt; 2e-16 ***\nDESTIN_SZCLSZ08   -0.4117031  0.0060602   -67.936  &lt; 2e-16 ***\nDESTIN_SZCLSZ09    0.2912807  0.0064319    45.287  &lt; 2e-16 ***\nDESTIN_SZDTSZ02   -2.8442617  0.0348408   -81.636  &lt; 2e-16 ***\nDESTIN_SZDTSZ03   -1.2900158  0.0144157   -89.487  &lt; 2e-16 ***\nDESTIN_SZDTSZ13   -1.9250557  0.0161488  -119.207  &lt; 2e-16 ***\nDESTIN_SZGLSZ01   -0.3326449  0.0051942   -64.042  &lt; 2e-16 ***\nDESTIN_SZGLSZ02   -0.3423980  0.0050258   -68.128  &lt; 2e-16 ***\nDESTIN_SZGLSZ03    0.6399801  0.0040595   157.648  &lt; 2e-16 ***\nDESTIN_SZGLSZ04    0.4841066  0.0040594   119.257  &lt; 2e-16 ***\nDESTIN_SZGLSZ05    0.6374564  0.0040657   156.788  &lt; 2e-16 ***\nDESTIN_SZHGSZ01    0.4187988  0.0039341   106.453  &lt; 2e-16 ***\nDESTIN_SZHGSZ02   -0.4492928  0.0054169   -82.943  &lt; 2e-16 ***\nDESTIN_SZHGSZ03   -0.8660435  0.0064195  -134.908  &lt; 2e-16 ***\nDESTIN_SZHGSZ04   -0.1355849  0.0045847   -29.573  &lt; 2e-16 ***\nDESTIN_SZHGSZ05   -0.1702976  0.0048822   -34.882  &lt; 2e-16 ***\nDESTIN_SZHGSZ06   -0.6791409  0.0057858  -117.380  &lt; 2e-16 ***\nDESTIN_SZHGSZ07    0.1120254  0.0045478    24.633  &lt; 2e-16 ***\nDESTIN_SZHGSZ08   -0.1462153  0.0050534   -28.934  &lt; 2e-16 ***\nDESTIN_SZHGSZ09    0.1478227  0.0052771    28.012  &lt; 2e-16 ***\nDESTIN_SZHGSZ10   -3.1620450  0.0262185  -120.603  &lt; 2e-16 ***\nDESTIN_SZJESZ01   -0.0793984  0.0050217   -15.811  &lt; 2e-16 ***\nDESTIN_SZJESZ02   -0.6066484  0.0052905  -114.667  &lt; 2e-16 ***\nDESTIN_SZJESZ03   -0.7509810  0.0057895  -129.713  &lt; 2e-16 ***\nDESTIN_SZJESZ04   -0.5953199  0.0068411   -87.022  &lt; 2e-16 ***\nDESTIN_SZJESZ05   -1.4256269  0.0098351  -144.953  &lt; 2e-16 ***\nDESTIN_SZJESZ06    0.0751565  0.0040942    18.357  &lt; 2e-16 ***\nDESTIN_SZJESZ07   -1.3271024  0.0081680  -162.476  &lt; 2e-16 ***\nDESTIN_SZJESZ08   -0.5102034  0.0079051   -64.541  &lt; 2e-16 ***\nDESTIN_SZJESZ09   -0.3313742  0.0058246   -56.892  &lt; 2e-16 ***\nDESTIN_SZJESZ10    0.4692055  0.0069809    67.213  &lt; 2e-16 ***\nDESTIN_SZJESZ11    0.7112949  0.0065922   107.899  &lt; 2e-16 ***\nDESTIN_SZJWSZ01   -0.2912848  0.0066150   -44.034  &lt; 2e-16 ***\nDESTIN_SZJWSZ02   -0.1925559  0.0053346   -36.096  &lt; 2e-16 ***\nDESTIN_SZJWSZ03    0.8519463  0.0041075   207.410  &lt; 2e-16 ***\nDESTIN_SZJWSZ04    0.4754181  0.0042941   110.714  &lt; 2e-16 ***\nDESTIN_SZJWSZ05   -0.4796359  0.0061325   -78.212  &lt; 2e-16 ***\nDESTIN_SZJWSZ06    0.0170339  0.0054886     3.103  0.00191 ** \nDESTIN_SZJWSZ07   -2.1279563  0.0282640   -75.289  &lt; 2e-16 ***\nDESTIN_SZJWSZ08    0.7195812  0.0049261   146.074  &lt; 2e-16 ***\nDESTIN_SZJWSZ09    1.3717249  0.0035293   388.672  &lt; 2e-16 ***\nDESTIN_SZKLSZ01   -0.7073464  0.0055551  -127.333  &lt; 2e-16 ***\nDESTIN_SZKLSZ02   -0.9229516  0.0058853  -156.824  &lt; 2e-16 ***\nDESTIN_SZKLSZ03   -1.3012706  0.0066470  -195.769  &lt; 2e-16 ***\nDESTIN_SZKLSZ04   -1.8810416  0.0088292  -213.047  &lt; 2e-16 ***\nDESTIN_SZKLSZ05   -0.6937362  0.0085722   -80.928  &lt; 2e-16 ***\nDESTIN_SZKLSZ06   -3.0430960  0.0362084   -84.044  &lt; 2e-16 ***\nDESTIN_SZKLSZ07   -1.3333100  0.0067161  -198.523  &lt; 2e-16 ***\nDESTIN_SZKLSZ08   -0.7646952  0.0052081  -146.829  &lt; 2e-16 ***\nDESTIN_SZLKSZ01   -0.9648136  0.0205558   -46.936  &lt; 2e-16 ***\nDESTIN_SZMDSZ01   -1.0428993  0.0200264   -52.076  &lt; 2e-16 ***\nDESTIN_SZMDSZ02   -1.0088343  0.0112070   -90.019  &lt; 2e-16 ***\nDESTIN_SZMDSZ03   -2.7184894  0.0252253  -107.768  &lt; 2e-16 ***\nDESTIN_SZMPSZ01   -0.5908399  0.0078467   -75.298  &lt; 2e-16 ***\nDESTIN_SZMPSZ02   -0.5390898  0.0061456   -87.720  &lt; 2e-16 ***\nDESTIN_SZMPSZ03    0.2913883  0.0048981    59.490  &lt; 2e-16 ***\nDESTIN_SZMUSZ02   -2.9286103  0.0199668  -146.674  &lt; 2e-16 ***\nDESTIN_SZNTSZ01   -4.0762244  0.0447769   -91.034  &lt; 2e-16 ***\nDESTIN_SZNTSZ02   -2.2875955  0.0108975  -209.919  &lt; 2e-16 ***\nDESTIN_SZNTSZ03   -1.7916106  0.0076808  -233.260  &lt; 2e-16 ***\nDESTIN_SZNTSZ05   -3.5218868  0.0249610  -141.096  &lt; 2e-16 ***\nDESTIN_SZNTSZ06   -4.2102393  0.0428640   -98.223  &lt; 2e-16 ***\nDESTIN_SZNVSZ01   -0.5511901  0.0048421  -113.832  &lt; 2e-16 ***\nDESTIN_SZNVSZ02   -0.6842973  0.0054368  -125.864  &lt; 2e-16 ***\nDESTIN_SZNVSZ03   -0.5113844  0.0055405   -92.300  &lt; 2e-16 ***\nDESTIN_SZNVSZ04   -1.9609701  0.0108861  -180.136  &lt; 2e-16 ***\nDESTIN_SZNVSZ05   -1.6282127  0.0090731  -179.456  &lt; 2e-16 ***\nDESTIN_SZPGSZ01   -1.0593679  0.0158155   -66.983  &lt; 2e-16 ***\nDESTIN_SZPGSZ02   -0.5795806  0.0069647   -83.217  &lt; 2e-16 ***\nDESTIN_SZPGSZ03    0.3909755  0.0045088    86.713  &lt; 2e-16 ***\nDESTIN_SZPGSZ04    0.4558243  0.0046315    98.419  &lt; 2e-16 ***\nDESTIN_SZPGSZ05   -0.5125145  0.0079058   -64.828  &lt; 2e-16 ***\nDESTIN_SZPLSZ01   -0.1333415  0.0071760   -18.582  &lt; 2e-16 ***\nDESTIN_SZPLSZ02   -0.9709255  0.0133073   -72.962  &lt; 2e-16 ***\nDESTIN_SZPLSZ03   -0.6085644  0.0095955   -63.422  &lt; 2e-16 ***\nDESTIN_SZPLSZ04   -2.7425007  0.0093816  -292.328  &lt; 2e-16 ***\nDESTIN_SZPLSZ05   -0.8417587  0.0117010   -71.939  &lt; 2e-16 ***\nDESTIN_SZPNSZ01   -0.0121813  0.0060751    -2.005  0.04495 *  \nDESTIN_SZPNSZ02    0.7631484  0.0064295   118.694  &lt; 2e-16 ***\nDESTIN_SZPNSZ03   -0.1043246  0.0076956   -13.556  &lt; 2e-16 ***\nDESTIN_SZPNSZ04    1.0351233  0.0075032   137.957  &lt; 2e-16 ***\nDESTIN_SZPNSZ05    0.2271643  0.0116266    19.538  &lt; 2e-16 ***\nDESTIN_SZPRSZ01   -0.6303237  0.0086378   -72.973  &lt; 2e-16 ***\nDESTIN_SZPRSZ02    0.2642641  0.0053008    49.854  &lt; 2e-16 ***\nDESTIN_SZPRSZ03    1.0170876  0.0039609   256.783  &lt; 2e-16 ***\nDESTIN_SZPRSZ04    0.2079891  0.0081112    25.642  &lt; 2e-16 ***\nDESTIN_SZPRSZ05    0.3417959  0.0049925    68.462  &lt; 2e-16 ***\nDESTIN_SZPRSZ06    0.5390524  0.0055203    97.650  &lt; 2e-16 ***\nDESTIN_SZPRSZ07   -1.9333913  0.0118415  -163.273  &lt; 2e-16 ***\nDESTIN_SZPRSZ08   -0.1910150  0.0065576   -29.129  &lt; 2e-16 ***\nDESTIN_SZQTSZ01   -1.3382706  0.0086422  -154.853  &lt; 2e-16 ***\nDESTIN_SZQTSZ02   -1.4965408  0.0074714  -200.304  &lt; 2e-16 ***\nDESTIN_SZQTSZ03   -1.3779365  0.0069203  -199.115  &lt; 2e-16 ***\nDESTIN_SZQTSZ04   -1.2773349  0.0068827  -185.586  &lt; 2e-16 ***\nDESTIN_SZQTSZ05   -1.3574169  0.0064940  -209.027  &lt; 2e-16 ***\nDESTIN_SZQTSZ06   -1.5263132  0.0067671  -225.549  &lt; 2e-16 ***\nDESTIN_SZQTSZ07   -1.9586230  0.0109634  -178.651  &lt; 2e-16 ***\nDESTIN_SZQTSZ08   -0.4303473  0.0051771   -83.125  &lt; 2e-16 ***\nDESTIN_SZQTSZ09   -0.8420154  0.0061124  -137.756  &lt; 2e-16 ***\nDESTIN_SZQTSZ10   -0.4557434  0.0055276   -82.448  &lt; 2e-16 ***\nDESTIN_SZQTSZ11   -0.3141765  0.0056414   -55.692  &lt; 2e-16 ***\nDESTIN_SZQTSZ12   -1.1034539  0.0082613  -133.569  &lt; 2e-16 ***\nDESTIN_SZQTSZ13   -0.2045638  0.0057646   -35.486  &lt; 2e-16 ***\nDESTIN_SZQTSZ14   -0.2763246  0.0066148   -41.774  &lt; 2e-16 ***\nDESTIN_SZQTSZ15    0.5654579  0.0078658    71.888  &lt; 2e-16 ***\nDESTIN_SZRCSZ01   -0.8221129  0.0071906  -114.331  &lt; 2e-16 ***\nDESTIN_SZRCSZ06   -1.5575544  0.0188859   -82.472  &lt; 2e-16 ***\nDESTIN_SZRVSZ01   -2.7796381  0.0162421  -171.138  &lt; 2e-16 ***\nDESTIN_SZRVSZ02   -2.8794393  0.0326171   -88.280  &lt; 2e-16 ***\nDESTIN_SZRVSZ03   -2.9115696  0.0136463  -213.359  &lt; 2e-16 ***\nDESTIN_SZRVSZ04   -2.5237482  0.0155011  -162.811  &lt; 2e-16 ***\nDESTIN_SZRVSZ05   -4.0058637  0.0262071  -152.854  &lt; 2e-16 ***\nDESTIN_SZSBSZ01   -1.2183497  0.0091460  -133.211  &lt; 2e-16 ***\nDESTIN_SZSBSZ02   -1.0903209  0.0077134  -141.354  &lt; 2e-16 ***\nDESTIN_SZSBSZ03    0.6055202  0.0043803   138.238  &lt; 2e-16 ***\nDESTIN_SZSBSZ04    0.3746039  0.0052892    70.824  &lt; 2e-16 ***\nDESTIN_SZSBSZ05   -1.0875343  0.0077022  -141.198  &lt; 2e-16 ***\nDESTIN_SZSBSZ06   -1.8270193  0.0221876   -82.344  &lt; 2e-16 ***\nDESTIN_SZSBSZ07   -0.5382117  0.0181906   -29.587  &lt; 2e-16 ***\nDESTIN_SZSBSZ08    1.1730685  0.0052334   224.150  &lt; 2e-16 ***\nDESTIN_SZSBSZ09    0.4129353  0.0048921    84.408  &lt; 2e-16 ***\nDESTIN_SZSESZ02    0.0934147  0.0049256    18.965  &lt; 2e-16 ***\nDESTIN_SZSESZ03    0.7697440  0.0038659   199.109  &lt; 2e-16 ***\nDESTIN_SZSESZ04   -0.4333259  0.0057461   -75.413  &lt; 2e-16 ***\nDESTIN_SZSESZ05   -0.1117549  0.0048635   -22.978  &lt; 2e-16 ***\nDESTIN_SZSESZ06   -0.3772855  0.0064222   -58.747  &lt; 2e-16 ***\nDESTIN_SZSESZ07   -2.8070689  0.0227290  -123.501  &lt; 2e-16 ***\nDESTIN_SZSGSZ01   -0.1312986  0.0058787   -22.334  &lt; 2e-16 ***\nDESTIN_SZSGSZ02    0.0097339  0.0052433     1.856  0.06339 .  \nDESTIN_SZSGSZ03   -0.1985918  0.0048763   -40.726  &lt; 2e-16 ***\nDESTIN_SZSGSZ04   -0.1421981  0.0049567   -28.688  &lt; 2e-16 ***\nDESTIN_SZSGSZ05   -2.1015053  0.0100493  -209.120  &lt; 2e-16 ***\nDESTIN_SZSGSZ06    0.4177334  0.0039114   106.800  &lt; 2e-16 ***\nDESTIN_SZSGSZ07   -0.5572004  0.0053060  -105.014  &lt; 2e-16 ***\nDESTIN_SZSISZ01   -1.6866922  0.0257825   -65.420  &lt; 2e-16 ***\nDESTIN_SZSKSZ01   -0.0547600  0.0072702    -7.532 4.99e-14 ***\nDESTIN_SZSKSZ02    1.2577275  0.0050573   248.697  &lt; 2e-16 ***\nDESTIN_SZSKSZ03    0.0986788  0.0059980    16.452  &lt; 2e-16 ***\nDESTIN_SZSKSZ04   -0.8889820  0.0140414   -63.311  &lt; 2e-16 ***\nDESTIN_SZSKSZ05   -0.2568016  0.0105209   -24.409  &lt; 2e-16 ***\nDESTIN_SZSLSZ01   -0.1895994  0.0083818   -22.620  &lt; 2e-16 ***\nDESTIN_SZSLSZ04   -0.3809817  0.0071348   -53.397  &lt; 2e-16 ***\nDESTIN_SZSRSZ01   -3.0146943  0.0130089  -231.740  &lt; 2e-16 ***\nDESTIN_SZTHSZ01   -3.1132404  0.0366860   -84.862  &lt; 2e-16 ***\nDESTIN_SZTHSZ03   -2.2150520  0.0251014   -88.244  &lt; 2e-16 ***\nDESTIN_SZTHSZ04   -2.7544085  0.0213728  -128.875  &lt; 2e-16 ***\nDESTIN_SZTHSZ06   -1.9539561  0.0153485  -127.306  &lt; 2e-16 ***\nDESTIN_SZTMSZ01    0.4897337  0.0055897    87.614  &lt; 2e-16 ***\nDESTIN_SZTMSZ02    1.9950293  0.0034804   573.219  &lt; 2e-16 ***\nDESTIN_SZTMSZ03    1.3339284  0.0039855   334.698  &lt; 2e-16 ***\nDESTIN_SZTMSZ04    1.6591506  0.0039214   423.105  &lt; 2e-16 ***\nDESTIN_SZTMSZ05    1.0962819  0.0056772   193.102  &lt; 2e-16 ***\nDESTIN_SZTNSZ01   -1.2211562  0.0071552  -170.666  &lt; 2e-16 ***\nDESTIN_SZTNSZ02   -2.3122987  0.0099124  -233.273  &lt; 2e-16 ***\nDESTIN_SZTNSZ03   -2.0866651  0.0117104  -178.189  &lt; 2e-16 ***\nDESTIN_SZTNSZ04   -1.0858305  0.0071883  -151.055  &lt; 2e-16 ***\nDESTIN_SZTPSZ01   -0.7136406  0.0059586  -119.767  &lt; 2e-16 ***\nDESTIN_SZTPSZ02    0.2420177  0.0038303    63.185  &lt; 2e-16 ***\nDESTIN_SZTPSZ03   -0.7530597  0.0056300  -133.758  &lt; 2e-16 ***\nDESTIN_SZTPSZ04   -1.7006370  0.0073620  -231.002  &lt; 2e-16 ***\nDESTIN_SZTPSZ05   -1.2310906  0.0058272  -211.267  &lt; 2e-16 ***\nDESTIN_SZTPSZ06   -0.8144830  0.0063418  -128.431  &lt; 2e-16 ***\nDESTIN_SZTPSZ07   -2.2661399  0.0116719  -194.154  &lt; 2e-16 ***\nDESTIN_SZTPSZ08   -1.6885660  0.0091067  -185.419  &lt; 2e-16 ***\nDESTIN_SZTPSZ09   -0.5642441  0.0067796   -83.227  &lt; 2e-16 ***\nDESTIN_SZTPSZ10   -1.5082863  0.0088455  -170.514  &lt; 2e-16 ***\nDESTIN_SZTPSZ11   -0.5583809  0.0053491  -104.388  &lt; 2e-16 ***\nDESTIN_SZTPSZ12   -0.9538104  0.0064014  -149.001  &lt; 2e-16 ***\nDESTIN_SZTSSZ01   -1.4451145  0.0208619   -69.270  &lt; 2e-16 ***\nDESTIN_SZTSSZ02   -0.4752373  0.0133278   -35.658  &lt; 2e-16 ***\nDESTIN_SZTSSZ03    0.6502289  0.0076057    85.492  &lt; 2e-16 ***\nDESTIN_SZTSSZ04    0.2845382  0.0079498    35.792  &lt; 2e-16 ***\nDESTIN_SZTSSZ05    1.1877409  0.0073930   160.657  &lt; 2e-16 ***\nDESTIN_SZTSSZ06    1.7332590  0.0140776   123.122  &lt; 2e-16 ***\nDESTIN_SZWCSZ01    2.6002592  0.0046409   560.287  &lt; 2e-16 ***\nDESTIN_SZWCSZ02   -0.6539688  0.0123673   -52.879  &lt; 2e-16 ***\nDESTIN_SZWCSZ03   -1.8564952  0.0325152   -57.096  &lt; 2e-16 ***\nDESTIN_SZWDSZ01    1.4131757  0.0035171   401.798  &lt; 2e-16 ***\nDESTIN_SZWDSZ02   -0.4605303  0.0059449   -77.467  &lt; 2e-16 ***\nDESTIN_SZWDSZ03    0.6847531  0.0045055   151.982  &lt; 2e-16 ***\nDESTIN_SZWDSZ04    0.0836263  0.0067610    12.369  &lt; 2e-16 ***\nDESTIN_SZWDSZ05    0.0772911  0.0066889    11.555  &lt; 2e-16 ***\nDESTIN_SZWDSZ06    0.4519395  0.0045580    99.153  &lt; 2e-16 ***\nDESTIN_SZWDSZ07   -0.4468713  0.0063890   -69.944  &lt; 2e-16 ***\nDESTIN_SZWDSZ08   -0.0566422  0.0062549    -9.056  &lt; 2e-16 ***\nDESTIN_SZWDSZ09    0.5814453  0.0046563   124.872  &lt; 2e-16 ***\nDESTIN_SZYSSZ01    0.9988417  0.0038893   256.819  &lt; 2e-16 ***\nDESTIN_SZYSSZ02    0.3934862  0.0051025    77.117  &lt; 2e-16 ***\nDESTIN_SZYSSZ03   -0.0879967  0.0061744   -14.252  &lt; 2e-16 ***\nDESTIN_SZYSSZ04   -0.0041863  0.0052771    -0.793  0.42761    \nDESTIN_SZYSSZ05   -0.9576475  0.0108533   -88.236  &lt; 2e-16 ***\nDESTIN_SZYSSZ06   -1.3716686  0.0106170  -129.195  &lt; 2e-16 ***\nDESTIN_SZYSSZ07   -0.8517973  0.0142269   -59.872  &lt; 2e-16 ***\nDESTIN_SZYSSZ08    1.0775536  0.0040061   268.980  &lt; 2e-16 ***\nDESTIN_SZYSSZ09    0.3694023  0.0042180    87.577  &lt; 2e-16 ***\nlog(SCHOOL_COUNT)         NA         NA        NA       NA    \nlog(DIST)         -1.7525619  0.0004141 -4231.928  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 47094011  on 14470  degrees of freedom\nResidual deviance: 18757606  on 14190  degrees of freedom\nAIC: 18847306\n\nNumber of Fisher Scoring iterations: 7\n\n\n\nGoodness-of-Fit\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.3735052"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#doubly-constrained",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#doubly-constrained",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Doubly Constrained",
    "text": "Doubly Constrained\n\ndbcSIM &lt;- glm(formula = TRIPS ~\n                ORIGIN_SZ +\n                DESTIN_SZ +\n                log(DIST),\n              family = poisson(link = \"log\"),\n              data = inter_zonal_flow,\n              na.action = na.exclude)\ndbcSIM\n\n\nCall:  glm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(DIST), family = poisson(link = \"log\"), \n    data = inter_zonal_flow, na.action = na.exclude)\n\nCoefficients:\n    (Intercept)  ORIGIN_SZAMSZ02  ORIGIN_SZAMSZ03  ORIGIN_SZAMSZ04  \n     21.8312374        0.5263502        0.3139982       -0.2146257  \nORIGIN_SZAMSZ05  ORIGIN_SZAMSZ06  ORIGIN_SZAMSZ07  ORIGIN_SZAMSZ08  \n     -0.1890446        0.1539201       -0.9826565       -0.4488417  \nORIGIN_SZAMSZ09  ORIGIN_SZAMSZ10  ORIGIN_SZAMSZ11  ORIGIN_SZAMSZ12  \n      0.0713474        0.4313742       -1.4712226       -1.7250733  \nORIGIN_SZBDSZ01  ORIGIN_SZBDSZ02  ORIGIN_SZBDSZ03  ORIGIN_SZBDSZ04  \n      0.8810576        0.1100240        0.3606166        1.4624347  \nORIGIN_SZBDSZ05  ORIGIN_SZBDSZ06  ORIGIN_SZBDSZ07  ORIGIN_SZBDSZ08  \n      0.6207557        0.6712973       -1.2338669       -1.0444562  \nORIGIN_SZBKSZ01  ORIGIN_SZBKSZ02  ORIGIN_SZBKSZ03  ORIGIN_SZBKSZ04  \n     -0.2838426        0.5550522        0.7396640       -0.2242451  \nORIGIN_SZBKSZ05  ORIGIN_SZBKSZ06  ORIGIN_SZBKSZ07  ORIGIN_SZBKSZ08  \n     -0.2371614       -0.1413812        0.7089989       -0.0907065  \nORIGIN_SZBKSZ09  ORIGIN_SZBLSZ01  ORIGIN_SZBLSZ02  ORIGIN_SZBLSZ03  \n     -0.1775146       -2.3684539       -2.8078475       -3.3122763  \nORIGIN_SZBLSZ04  ORIGIN_SZBMSZ01  ORIGIN_SZBMSZ02  ORIGIN_SZBMSZ03  \n     -2.6770542        0.0618035       -1.3535767       -0.7569095  \nORIGIN_SZBMSZ04  ORIGIN_SZBMSZ05  ORIGIN_SZBMSZ06  ORIGIN_SZBMSZ07  \n     -0.2949304       -2.6131992       -3.0315024       -0.6962524  \nORIGIN_SZBMSZ08  ORIGIN_SZBMSZ09  ORIGIN_SZBMSZ10  ORIGIN_SZBMSZ11  \n     -0.9310730       -1.2911253       -1.6687004       -1.1152794  \nORIGIN_SZBMSZ12  ORIGIN_SZBMSZ13  ORIGIN_SZBMSZ14  ORIGIN_SZBMSZ15  \n     -1.5323954       -0.6267376       -1.0475467       -0.5049444  \nORIGIN_SZBMSZ16  ORIGIN_SZBMSZ17  ORIGIN_SZBPSZ01  ORIGIN_SZBPSZ02  \n     -1.5282897       -1.5722349        0.5814175        0.0875442  \nORIGIN_SZBPSZ03  ORIGIN_SZBPSZ04  ORIGIN_SZBPSZ05  ORIGIN_SZBPSZ06  \n      0.3358227        0.6507586        0.9502124       -1.0480314  \nORIGIN_SZBPSZ07  ORIGIN_SZBSSZ01  ORIGIN_SZBSSZ02  ORIGIN_SZBSSZ03  \n     -0.5467931        0.2998334        0.2841036       -0.2331505  \nORIGIN_SZBTSZ01  ORIGIN_SZBTSZ02  ORIGIN_SZBTSZ03  ORIGIN_SZBTSZ04  \n      0.0987284       -0.6261229       -0.4326963       -1.4998668  \nORIGIN_SZBTSZ05  ORIGIN_SZBTSZ06  ORIGIN_SZBTSZ07  ORIGIN_SZBTSZ08  \n     -0.9564768       -1.2853131       -2.3870991       -1.3715855  \nORIGIN_SZCBSZ01  ORIGIN_SZCCSZ01  ORIGIN_SZCHSZ01  ORIGIN_SZCHSZ02  \n     -3.5940232       -0.7008220       -0.9109524       -0.8566547  \nORIGIN_SZCHSZ03  ORIGIN_SZCKSZ01  ORIGIN_SZCKSZ02  ORIGIN_SZCKSZ03  \n      1.1153731        0.3001815        0.7185711        1.1389824  \nORIGIN_SZCKSZ04  ORIGIN_SZCKSZ05  ORIGIN_SZCKSZ06  ORIGIN_SZCLSZ01  \n      1.6281772        0.8338470        0.6528993       -0.7174758  \nORIGIN_SZCLSZ02  ORIGIN_SZCLSZ03  ORIGIN_SZCLSZ04  ORIGIN_SZCLSZ05  \n     -1.7513100       -1.0362873        0.6160017       -2.1005122  \nORIGIN_SZCLSZ06  ORIGIN_SZCLSZ07  ORIGIN_SZCLSZ08  ORIGIN_SZCLSZ09  \n      0.7252108       -0.5343482       -0.2153408       -1.8019961  \nORIGIN_SZDTSZ02  ORIGIN_SZDTSZ03  ORIGIN_SZDTSZ13  ORIGIN_SZGLSZ01  \n     -3.9057711       -3.4152419       -3.0183438       -1.7812384  \nORIGIN_SZGLSZ02  ORIGIN_SZGLSZ03  ORIGIN_SZGLSZ04  ORIGIN_SZGLSZ05  \n     -0.1074991       -0.2461106        0.8657186        0.5871393  \nORIGIN_SZHGSZ01  ORIGIN_SZHGSZ02  ORIGIN_SZHGSZ03  ORIGIN_SZHGSZ04  \n      0.3543819        0.4218178        0.2411309        0.8180622  \nORIGIN_SZHGSZ05  ORIGIN_SZHGSZ06  ORIGIN_SZHGSZ07  ORIGIN_SZHGSZ08  \n      1.2173687       -0.1826300        0.3172839       -0.1151369  \nORIGIN_SZHGSZ09  ORIGIN_SZHGSZ10  ORIGIN_SZJESZ01  ORIGIN_SZJESZ02  \n     -1.2873441       -3.3783178        0.4859234        0.1766088  \nORIGIN_SZJESZ03  ORIGIN_SZJESZ04  ORIGIN_SZJESZ05  ORIGIN_SZJESZ06  \n     -0.2177441       -1.5532182       -2.3332926        0.3007382  \nORIGIN_SZJESZ07  ORIGIN_SZJESZ08  ORIGIN_SZJESZ09  ORIGIN_SZJESZ10  \n     -1.9687994       -1.3032070        0.5762635       -1.4423113  \nORIGIN_SZJESZ11  ORIGIN_SZJWSZ01  ORIGIN_SZJWSZ02  ORIGIN_SZJWSZ03  \n     -1.9720897        0.3808627        0.7963999        1.5429636  \nORIGIN_SZJWSZ04  ORIGIN_SZJWSZ05  ORIGIN_SZJWSZ06  ORIGIN_SZJWSZ07  \n      0.6410760       -2.1571049       -1.5174532       -2.7089963  \nORIGIN_SZJWSZ08  ORIGIN_SZJWSZ09  ORIGIN_SZKLSZ01  ORIGIN_SZKLSZ02  \n      1.5343415        1.8837410        0.1081286       -0.8844695  \nORIGIN_SZKLSZ03  ORIGIN_SZKLSZ04  ORIGIN_SZKLSZ05  ORIGIN_SZKLSZ06  \n     -0.6872640       -2.2090319       -1.1728726       -6.1162315  \nORIGIN_SZKLSZ07  ORIGIN_SZKLSZ08  ORIGIN_SZLKSZ01  ORIGIN_SZMDSZ01  \n     -1.4082749       -1.7781551       -2.0531568       -0.8825639  \nORIGIN_SZMDSZ02  ORIGIN_SZMDSZ03  ORIGIN_SZMPSZ01  ORIGIN_SZMPSZ02  \n     -0.6219993       -2.0840156       -0.9659093       -1.0411153  \nORIGIN_SZMPSZ03  ORIGIN_SZMUSZ02  ORIGIN_SZNTSZ01  ORIGIN_SZNTSZ02  \n      0.0001659       -3.7599031       -3.0388366       -3.4230640  \nORIGIN_SZNTSZ03  ORIGIN_SZNTSZ05  ORIGIN_SZNTSZ06  ORIGIN_SZNVSZ01  \n     -0.9094796       -4.0861681       -3.9497128        0.3235636  \nORIGIN_SZNVSZ02  ORIGIN_SZNVSZ03  ORIGIN_SZNVSZ04  ORIGIN_SZNVSZ05  \n     -0.6946748       -1.0540196       -0.9897977       -2.2578432  \nORIGIN_SZPGSZ01  ORIGIN_SZPGSZ02  ORIGIN_SZPGSZ03  ORIGIN_SZPGSZ04  \n      0.2399827       -0.3352342        0.9515148        1.3998952  \nORIGIN_SZPGSZ05  ORIGIN_SZPLSZ01  ORIGIN_SZPLSZ02  ORIGIN_SZPLSZ03  \n      0.4451629       -0.9705918       -1.0670151       -2.1229124  \nORIGIN_SZPLSZ04  ORIGIN_SZPLSZ05  ORIGIN_SZPNSZ01  ORIGIN_SZPNSZ02  \n     -3.0911932       -2.1705708        0.9052637       -0.1720425  \nORIGIN_SZPNSZ03  ORIGIN_SZPNSZ04  ORIGIN_SZPNSZ05  ORIGIN_SZPRSZ01  \n     -2.3973459       -3.4483689       -2.0588530       -0.6399015  \nORIGIN_SZPRSZ02  ORIGIN_SZPRSZ03  ORIGIN_SZPRSZ04  ORIGIN_SZPRSZ05  \n      0.8122270        0.3990960       -0.8485348        0.8008791  \nORIGIN_SZPRSZ06  ORIGIN_SZPRSZ07  ORIGIN_SZPRSZ08  ORIGIN_SZQTSZ01  \n     -1.4498806       -3.2025045       -0.5862269       -0.1859270  \nORIGIN_SZQTSZ02  ORIGIN_SZQTSZ03  ORIGIN_SZQTSZ04  ORIGIN_SZQTSZ05  \n     -0.8715122       -0.1259816       -1.4620032       -0.6675643  \nORIGIN_SZQTSZ06  ORIGIN_SZQTSZ07  ORIGIN_SZQTSZ08  ORIGIN_SZQTSZ09  \n     -0.8190026       -1.5189403       -0.4976238       -0.9006162  \nORIGIN_SZQTSZ10  ORIGIN_SZQTSZ11  ORIGIN_SZQTSZ12  ORIGIN_SZQTSZ13  \n     -0.6690184       -2.5203437       -3.0461675       -0.7501068  \nORIGIN_SZQTSZ14  ORIGIN_SZQTSZ15  ORIGIN_SZRCSZ01  ORIGIN_SZRCSZ06  \n     -1.9321849       -0.9576828       -1.8167951       -0.5560563  \nORIGIN_SZRVSZ01  ORIGIN_SZRVSZ02  ORIGIN_SZRVSZ03  ORIGIN_SZRVSZ04  \n     -2.8862570       -3.1555662       -2.9836089       -3.5520422  \nORIGIN_SZRVSZ05  ORIGIN_SZSBSZ01  ORIGIN_SZSBSZ02  ORIGIN_SZSBSZ03  \n     -2.5866584        0.2867444       -0.9012334        0.8311038  \nORIGIN_SZSBSZ04  ORIGIN_SZSBSZ05  ORIGIN_SZSBSZ06  ORIGIN_SZSBSZ07  \n      0.4044170       -0.2661845       -0.9023075        0.0505870  \nORIGIN_SZSBSZ08  ORIGIN_SZSBSZ09  ORIGIN_SZSESZ02  ORIGIN_SZSESZ03  \n     -1.1158011       -0.9682835        1.1452735        1.2815277  \nORIGIN_SZSESZ04  ORIGIN_SZSESZ05  ORIGIN_SZSESZ06  ORIGIN_SZSESZ07  \n      0.8085857       -0.2329413        1.0576879       -2.3165908  \nORIGIN_SZSGSZ01  ORIGIN_SZSGSZ02  ORIGIN_SZSGSZ03  ORIGIN_SZSGSZ04  \n     -0.6606350       -1.3638984        0.1152591        0.2954067  \nORIGIN_SZSGSZ05  ORIGIN_SZSGSZ06  ORIGIN_SZSGSZ07  ORIGIN_SZSKSZ01  \n     -2.0792678        0.4563227       -0.8955254       -0.3184402  \nORIGIN_SZSKSZ02  ORIGIN_SZSKSZ03  ORIGIN_SZSKSZ04  ORIGIN_SZSKSZ05  \n      1.1160484       -0.2566692       -1.5781827       -0.2724361  \nORIGIN_SZSLSZ01  ORIGIN_SZSLSZ04  ORIGIN_SZSRSZ01  ORIGIN_SZTHSZ01  \n     -2.4458625       -0.0987076       -2.2584977       -2.5878524  \nORIGIN_SZTHSZ03  ORIGIN_SZTHSZ04  ORIGIN_SZTHSZ06  ORIGIN_SZTMSZ01  \n     -0.8101746       -2.4186655       -1.7080541       -0.2193476  \nORIGIN_SZTMSZ02  ORIGIN_SZTMSZ03  ORIGIN_SZTMSZ04  ORIGIN_SZTMSZ05  \n      1.7772464        1.0051343        0.1642370       -1.2878706  \nORIGIN_SZTNSZ01  ORIGIN_SZTNSZ02  ORIGIN_SZTNSZ03  ORIGIN_SZTNSZ04  \n     -1.7163504       -1.6508988       -2.1545577       -0.3949120  \nORIGIN_SZTPSZ01  ORIGIN_SZTPSZ02  ORIGIN_SZTPSZ03  ORIGIN_SZTPSZ04  \n     -0.8058100        0.5369060       -0.7779333       -0.8153581  \nORIGIN_SZTPSZ05  ORIGIN_SZTPSZ06  ORIGIN_SZTPSZ07  ORIGIN_SZTPSZ08  \n     -0.5073676        0.0847301       -0.5839519       -1.0577941  \nORIGIN_SZTPSZ09  ORIGIN_SZTPSZ10  ORIGIN_SZTPSZ11  ORIGIN_SZTPSZ12  \n     -0.9067707       -1.1362091       -0.2374621       -0.8028874  \nORIGIN_SZTSSZ01  ORIGIN_SZTSSZ02  ORIGIN_SZTSSZ03  ORIGIN_SZTSSZ04  \n     -2.7809271        0.0425804        0.1142369       -0.6186261  \nORIGIN_SZTSSZ05  ORIGIN_SZTSSZ06  ORIGIN_SZWCSZ01  ORIGIN_SZWCSZ02  \n     -1.0846732        0.3980173        1.3545143       -2.9863278  \nORIGIN_SZWCSZ03  ORIGIN_SZWDSZ01  ORIGIN_SZWDSZ02  ORIGIN_SZWDSZ03  \n     -5.0504916        1.5238429        0.2832576        1.3702524  \nORIGIN_SZWDSZ04  ORIGIN_SZWDSZ05  ORIGIN_SZWDSZ06  ORIGIN_SZWDSZ07  \n      1.0248225        0.2356778        0.3146925       -1.4971897  \nORIGIN_SZWDSZ08  ORIGIN_SZWDSZ09  ORIGIN_SZYSSZ01  ORIGIN_SZYSSZ02  \n     -0.8894079        1.4437633       -0.2519398        0.8726785  \nORIGIN_SZYSSZ03  ORIGIN_SZYSSZ04  ORIGIN_SZYSSZ05  ORIGIN_SZYSSZ06  \n      1.7868139        0.8418040        0.4292096       -0.7459961  \nORIGIN_SZYSSZ07  ORIGIN_SZYSSZ08  ORIGIN_SZYSSZ09  DESTIN_SZAMSZ02  \n     -0.8422281        0.1829428        1.1159712        0.0694567  \nDESTIN_SZAMSZ03  DESTIN_SZAMSZ04  DESTIN_SZAMSZ05  DESTIN_SZAMSZ06  \n      0.0760100       -1.1306391       -1.0751133       -0.9624298  \nDESTIN_SZAMSZ07  DESTIN_SZAMSZ08  DESTIN_SZAMSZ09  DESTIN_SZAMSZ10  \n     -1.5060319       -0.4813202       -1.0220675        0.1235142  \nDESTIN_SZAMSZ11  DESTIN_SZAMSZ12  DESTIN_SZBDSZ01  DESTIN_SZBDSZ02  \n     -0.8917993        0.0195208        0.9736349       -0.1969470  \nDESTIN_SZBDSZ03  DESTIN_SZBDSZ04  DESTIN_SZBDSZ05  DESTIN_SZBDSZ06  \n      0.1266471        1.1608485        0.9293840        0.4090567  \nDESTIN_SZBDSZ07  DESTIN_SZBDSZ08  DESTIN_SZBKSZ01  DESTIN_SZBKSZ02  \n     -0.8171478       -1.5895287       -1.3793311       -0.5253670  \nDESTIN_SZBKSZ03  DESTIN_SZBKSZ04  DESTIN_SZBKSZ05  DESTIN_SZBKSZ06  \n     -1.0095362       -0.5662858       -0.9406607       -1.3129276  \nDESTIN_SZBKSZ07  DESTIN_SZBKSZ08  DESTIN_SZBKSZ09  DESTIN_SZBLSZ01  \n      0.0120605       -1.3658471       -0.1771310       -0.8175223  \nDESTIN_SZBLSZ02  DESTIN_SZBLSZ03  DESTIN_SZBLSZ04  DESTIN_SZBMSZ01  \n      0.1631280        1.2598494       -0.5642975        0.6921844  \nDESTIN_SZBMSZ02  DESTIN_SZBMSZ03  DESTIN_SZBMSZ04  DESTIN_SZBMSZ05  \n     -0.1209392       -0.2373881       -0.0407117       -0.2363309  \nDESTIN_SZBMSZ06  DESTIN_SZBMSZ07  DESTIN_SZBMSZ08  DESTIN_SZBMSZ09  \n     -1.1930710        0.4625103       -0.8604731       -2.1290239  \nDESTIN_SZBMSZ10  DESTIN_SZBMSZ11  DESTIN_SZBMSZ12  DESTIN_SZBMSZ13  \n     -1.4617153       -1.3234050       -0.8399230        0.1366529  \nDESTIN_SZBMSZ14  DESTIN_SZBMSZ15  DESTIN_SZBMSZ16  DESTIN_SZBMSZ17  \n     -1.0491968       -0.6726684       -1.4011734       -1.5682752  \nDESTIN_SZBPSZ01  DESTIN_SZBPSZ02  DESTIN_SZBPSZ03  DESTIN_SZBPSZ04  \n     -1.1120017       -2.0833466       -1.6937265       -0.7964999  \nDESTIN_SZBPSZ05  DESTIN_SZBPSZ06  DESTIN_SZBPSZ07  DESTIN_SZBSSZ01  \n      0.2109118       -1.1808365       -0.2077428        0.3164175  \nDESTIN_SZBSSZ02  DESTIN_SZBSSZ03  DESTIN_SZBTSZ01  DESTIN_SZBTSZ02  \n     -0.4852688        0.4130432        0.6215095       -0.0145076  \nDESTIN_SZBTSZ03  DESTIN_SZBTSZ04  DESTIN_SZBTSZ05  DESTIN_SZBTSZ06  \n      0.4919981       -0.6957555        0.3329814       -0.1333295  \nDESTIN_SZBTSZ07  DESTIN_SZBTSZ08  DESTIN_SZCBSZ01  DESTIN_SZCCSZ01  \n     -1.4449581       -0.7079056       -5.7344725       -0.0009541  \nDESTIN_SZCHSZ01  DESTIN_SZCHSZ02  DESTIN_SZCHSZ03  DESTIN_SZCKSZ01  \n     -0.2083016        0.5369606        2.5530638       -0.5725975  \nDESTIN_SZCKSZ02  DESTIN_SZCKSZ03  DESTIN_SZCKSZ04  DESTIN_SZCKSZ05  \n     -1.1181852        0.1156680       -0.8647725       -1.1641791  \nDESTIN_SZCKSZ06  DESTIN_SZCLSZ01  DESTIN_SZCLSZ02  DESTIN_SZCLSZ03  \n     -0.4397612        0.1930552       -2.0436501       -0.9338571  \nDESTIN_SZCLSZ04  DESTIN_SZCLSZ05  DESTIN_SZCLSZ06  DESTIN_SZCLSZ07  \n      0.0532041       -1.0782781        0.4068171       -0.3579507  \nDESTIN_SZCLSZ08  DESTIN_SZCLSZ09  DESTIN_SZDTSZ02  DESTIN_SZDTSZ03  \n     -0.2487993        0.1611080       -1.7308348       -0.5994253  \nDESTIN_SZDTSZ13  DESTIN_SZGLSZ01  DESTIN_SZGLSZ02  DESTIN_SZGLSZ03  \n     -1.3685031       -0.0910001       -0.0692224        0.6493421  \nDESTIN_SZGLSZ04  DESTIN_SZGLSZ05  DESTIN_SZHGSZ01  DESTIN_SZHGSZ02  \n      0.9327947        0.8161728        0.0658625       -0.8134329  \nDESTIN_SZHGSZ03  DESTIN_SZHGSZ04  DESTIN_SZHGSZ05  DESTIN_SZHGSZ06  \n     -1.3546132       -0.4500588       -0.5026431       -0.8673686  \nDESTIN_SZHGSZ07  DESTIN_SZHGSZ08  DESTIN_SZHGSZ09  DESTIN_SZHGSZ10  \n      0.0560490       -0.0443189       -0.0126355       -3.5821793  \nDESTIN_SZJESZ01  DESTIN_SZJESZ02  DESTIN_SZJESZ03  DESTIN_SZJESZ04  \n     -0.3704281       -0.7369159       -0.8985484       -1.0511995  \nDESTIN_SZJESZ05  DESTIN_SZJESZ06  DESTIN_SZJESZ07  DESTIN_SZJESZ08  \n     -1.5324974        0.3105267       -1.3234483       -0.6559742  \nDESTIN_SZJESZ09  DESTIN_SZJESZ10  DESTIN_SZJESZ11  DESTIN_SZJWSZ01  \n      0.2663752        0.8529026        0.5559641       -0.9790971  \nDESTIN_SZJWSZ02  DESTIN_SZJWSZ03  DESTIN_SZJWSZ04  DESTIN_SZJWSZ05  \n     -0.8746590        0.5689062        0.4520963       -1.0249671  \nDESTIN_SZJWSZ06  DESTIN_SZJWSZ07  DESTIN_SZJWSZ08  DESTIN_SZJWSZ09  \n     -0.7451483       -2.8453099       -0.3372309        1.0505330  \nDESTIN_SZKLSZ01  DESTIN_SZKLSZ02  DESTIN_SZKLSZ03  DESTIN_SZKLSZ04  \n     -0.2334836       -0.5416148       -0.8026495       -1.2918594  \nDESTIN_SZKLSZ05  DESTIN_SZKLSZ06  DESTIN_SZKLSZ07  DESTIN_SZKLSZ08  \n     -0.4069101       -2.5333101       -0.6623343       -0.1408205  \nDESTIN_SZLKSZ01  DESTIN_SZMDSZ01  DESTIN_SZMDSZ02  DESTIN_SZMDSZ03  \n     -1.2639235       -1.5655800       -0.9767682       -3.3328109  \nDESTIN_SZMPSZ01  DESTIN_SZMPSZ02  DESTIN_SZMPSZ03  DESTIN_SZMUSZ02  \n     -0.4552859       -0.5386560        0.4952000       -1.4434175  \nDESTIN_SZNTSZ01  DESTIN_SZNTSZ02  DESTIN_SZNTSZ03  DESTIN_SZNTSZ05  \n     -2.9194067       -1.3780179       -0.5044699       -2.0017134  \nDESTIN_SZNTSZ06  DESTIN_SZNVSZ01  DESTIN_SZNVSZ02  DESTIN_SZNVSZ03  \n     -3.8120537       -0.1071506       -0.0274710        0.1076352  \nDESTIN_SZNVSZ04  DESTIN_SZNVSZ05  DESTIN_SZPGSZ01  DESTIN_SZPGSZ02  \n     -1.2087250       -1.0058290       -1.2029931       -1.2878671  \nDESTIN_SZPGSZ03  DESTIN_SZPGSZ04  DESTIN_SZPGSZ05  DESTIN_SZPLSZ01  \n     -0.1520894       -0.1985959       -1.5290983       -0.3567934  \nDESTIN_SZPLSZ02  DESTIN_SZPLSZ03  DESTIN_SZPLSZ04  DESTIN_SZPLSZ05  \n     -1.7114351       -0.3241427       -1.7117196       -0.5086379  \nDESTIN_SZPNSZ01  DESTIN_SZPNSZ02  DESTIN_SZPNSZ03  DESTIN_SZPNSZ04  \n      0.2026781        0.8313754       -0.4041254        1.5814539  \nDESTIN_SZPNSZ05  DESTIN_SZPRSZ01  DESTIN_SZPRSZ02  DESTIN_SZPRSZ03  \n      1.1823430       -1.1057553        0.0895099        0.6921925  \nDESTIN_SZPRSZ04  DESTIN_SZPRSZ05  DESTIN_SZPRSZ06  DESTIN_SZPRSZ07  \n     -0.2848336        0.1744480        0.4279206       -1.5123108  \nDESTIN_SZPRSZ08  DESTIN_SZQTSZ01  DESTIN_SZQTSZ02  DESTIN_SZQTSZ03  \n     -0.5650226       -0.5952360       -0.7728170       -0.5066812  \nDESTIN_SZQTSZ04  DESTIN_SZQTSZ05  DESTIN_SZQTSZ06  DESTIN_SZQTSZ07  \n     -0.6398414       -0.4354527       -0.6597391       -0.9392696  \nDESTIN_SZQTSZ08  DESTIN_SZQTSZ09  DESTIN_SZQTSZ10  DESTIN_SZQTSZ11  \n      0.4617774       -0.3174497        0.1993449        0.2551535  \nDESTIN_SZQTSZ12  DESTIN_SZQTSZ13  DESTIN_SZQTSZ14  DESTIN_SZQTSZ15  \n     -0.1662603        0.5500978        0.5364435        1.3611043  \nDESTIN_SZRCSZ01  DESTIN_SZRCSZ06  DESTIN_SZRVSZ01  DESTIN_SZRVSZ02  \n     -0.1034049       -1.0633902       -1.5486221       -2.4092611  \nDESTIN_SZRVSZ03  DESTIN_SZRVSZ04  DESTIN_SZRVSZ05  DESTIN_SZSBSZ01  \n     -1.5172079       -1.1663615       -2.2404292       -1.3783780  \nDESTIN_SZSBSZ02  DESTIN_SZSBSZ03  DESTIN_SZSBSZ04  DESTIN_SZSBSZ05  \n     -1.4445213        0.5149906        0.2389086       -1.2737442  \nDESTIN_SZSBSZ06  DESTIN_SZSBSZ07  DESTIN_SZSBSZ08  DESTIN_SZSBSZ09  \n     -1.8683520       -0.5993154        0.8156302        0.0900611  \nDESTIN_SZSESZ02  DESTIN_SZSESZ03  DESTIN_SZSESZ04  DESTIN_SZSESZ05  \n     -0.6397704        0.1714103       -1.0596175       -0.8071891  \nDESTIN_SZSESZ06  DESTIN_SZSESZ07  DESTIN_SZSGSZ01  DESTIN_SZSGSZ02  \n     -0.5580934       -3.1448863       -0.1795225       -0.2986570  \nDESTIN_SZSGSZ03  DESTIN_SZSGSZ04  DESTIN_SZSGSZ05  DESTIN_SZSGSZ06  \n     -0.4074671       -0.1505164       -1.9908372        0.6715268  \nDESTIN_SZSGSZ07  DESTIN_SZSISZ01  DESTIN_SZSKSZ01  DESTIN_SZSKSZ02  \n     -0.4494757       -0.5517983       -0.4749154        0.9400302  \nDESTIN_SZSKSZ03  DESTIN_SZSKSZ04  DESTIN_SZSKSZ05  DESTIN_SZSLSZ01  \n     -0.2800377       -1.2570212       -0.2600474       -0.7775604  \nDESTIN_SZSLSZ04  DESTIN_SZSRSZ01  DESTIN_SZTHSZ01  DESTIN_SZTHSZ03  \n     -0.8586515       -1.1370887       -4.3259988       -2.6632914  \nDESTIN_SZTHSZ04  DESTIN_SZTHSZ06  DESTIN_SZTMSZ01  DESTIN_SZTMSZ02  \n     -3.1000906       -2.5952642       -0.2092828        1.8238139  \nDESTIN_SZTMSZ03  DESTIN_SZTMSZ04  DESTIN_SZTMSZ05  DESTIN_SZTNSZ01  \n      0.8518259        1.0222812        0.6323777       -0.3336078  \nDESTIN_SZTNSZ02  DESTIN_SZTNSZ03  DESTIN_SZTNSZ04  DESTIN_SZTPSZ01  \n     -1.0820469       -1.4186505       -0.3058199       -0.4872299  \nDESTIN_SZTPSZ02  DESTIN_SZTPSZ03  DESTIN_SZTPSZ04  DESTIN_SZTPSZ05  \n      0.7158441       -0.4314229       -1.5898245       -1.0445550  \nDESTIN_SZTPSZ06  DESTIN_SZTPSZ07  DESTIN_SZTPSZ08  DESTIN_SZTPSZ09  \n     -0.4319582       -2.1602303       -1.1920493       -0.2022481  \nDESTIN_SZTPSZ10  DESTIN_SZTPSZ11  DESTIN_SZTPSZ12  DESTIN_SZTSSZ01  \n     -1.2464793       -0.0808445       -0.6784376       -1.5845062  \nDESTIN_SZTSSZ02  DESTIN_SZTSSZ03  DESTIN_SZTSSZ04  DESTIN_SZTSSZ05  \n     -0.1886010        0.6525526        0.5285464        1.4670106  \nDESTIN_SZTSSZ06  DESTIN_SZWCSZ01  DESTIN_SZWCSZ02  DESTIN_SZWCSZ03  \n      2.5043588        1.9787931       -2.2593108       -3.1897655  \nDESTIN_SZWDSZ01  DESTIN_SZWDSZ02  DESTIN_SZWDSZ03  DESTIN_SZWDSZ04  \n      1.0476108       -1.3176990        0.3432057       -0.7895927  \nDESTIN_SZWDSZ05  DESTIN_SZWDSZ06  DESTIN_SZWDSZ07  DESTIN_SZWDSZ08  \n     -0.8751665       -0.2106221       -1.6050834       -0.5124717  \nDESTIN_SZWDSZ09  DESTIN_SZYSSZ01  DESTIN_SZYSSZ02  DESTIN_SZYSSZ03  \n      0.3813542        0.0853753       -0.3227172       -0.4151283  \nDESTIN_SZYSSZ04  DESTIN_SZYSSZ05  DESTIN_SZYSSZ06  DESTIN_SZYSSZ07  \n     -0.4637327       -1.5888242       -1.4606209       -0.7839065  \nDESTIN_SZYSSZ08  DESTIN_SZYSSZ09        log(DIST)  \n      0.6265412        0.1520067       -1.8468315  \n\nDegrees of Freedom: 14470 Total (i.e. Null);  13912 Residual\nNull Deviance:      47090000 \nResidual Deviance: 10420000     AIC: 10510000\n\n\n\nGoodness-of-Fit\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.7001882"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#model-comparison",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#model-comparison",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Model Comparison",
    "text": "Model Comparison\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 3198.736\noriginConstrained      |   glm | 2613.236\ndestinationConstrained |   glm | 2754.902\ndoublyConstrained      |   glm | 1906.694"
  },
  {
    "objectID": "In-Class_Ex_4/In-Class_Ex_4.html#visualising-fitted",
    "href": "In-Class_Ex_4/In-Class_Ex_4.html#visualising-fitted",
    "title": "In class Exercise 4: GeoSpatial Data Science with R",
    "section": "Visualising Fitted",
    "text": "Visualising Fitted\nExtract the fitted values from each model\nUnconstraint Model\n\ndf_unc &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\ndf_orc &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\ndf_dec &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\ndf_dbc &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\ninter_zonal_flow &lt;- inter_zonal_flow %&gt;%\n  cbind(df_unc) %&gt;%\n  cbind(df_orc) %&gt;%\n  cbind(df_dec) %&gt;%\n  cbind(df_dbc) %&gt;%\n  rename(uncTRIPS = `uncSIM.fitted.values`,\n         orcTRIPS = `orcSIM.fitted.values`,\n         decTRIPS = `decSIM.fitted.values`,\n         dbcTRIPS = `dbcSIM.fitted.values`)\n\nPlotting graphs\n\nlibrary(patchwork)\n\n# 创建单独的ggplot对象\nunc_p &lt;- ggplot(data = inter_zonal_flow,\n                aes(x = uncTRIPS, y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = inter_zonal_flow,\n                aes(x = orcTRIPS, y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = inter_zonal_flow,\n                aes(x = decTRIPS, y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = inter_zonal_flow,\n                aes(x = dbcTRIPS, y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n# 使用patchwork组合图表\ncombined_plot &lt;- (unc_p | orc_p) / \n                 (dec_p | dbc_p)\n\n# 显示组合图表\ncombined_plot\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# 保存组合图表到文件\nggsave(\"combined_plot.png\", combined_plot, width = 20, height = 15, units = \"cm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html",
    "title": "Take-Home_Exercise_2",
    "section": "",
    "text": "Despite the increasing amount of open data available for public consumption, significant practical research has not yet been conducted to demonstrate how these disparate data sources can be integrated, analyzed, and modeled to support policy-making decisions. There is a general lack of practical research demonstrating how geospatial data science and analytics (GDSA) can be used to support decision-making.\n\n\n\nThe purpose of this analysis is to conduct a case study to demonstrate the potential value of GDSA to integrate publicly available data from multiple sources to build a spatial interaction model to identify factors influencing public transport urban traffic patterns.\n\n\n\nDerive an analytical hexagon data of 325m (this distance is the perpendicular distance between the centre of the hexagon and its edges) to represent the traffic analysis zone (TAZ).\nWith reference to the time intervals provided in the table below, construct an O-D matrix of commuter flows for a time interval of your choice by integrating Passenger Volume by Origin Destination Bus Stops and Bus Stop Location from LTA DataMall. The O-D matrix must be aggregated at the analytics hexagon level\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the O-D flows of the passenger trips by using appropriate geovisualisation methods (not more than 5 maps).\nDescribe the spatial patterns revealed by the geovisualisation (not more than 100 words per visual).\nAssemble at least three propulsive and three attractiveness variables by using aspatial and geospatial from publicly available sources.\nCompute a distance matrix by using the analytical hexagon data derived earlier.\n\n\n\n\n\nCalibrate spatial interactive models to determine factors affecting urban commuting flows at the selected time interval.\nPresent the modelling results by using appropriate geovisualisation and graphical visualisation methods. (Not more than 5 visuals)\nWith reference to the Spatial Interaction Model output tables, maps and data visualisation prepared, describe the modelling results. (not more than 100 words per visual)."
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#background",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#background",
    "title": "Take-Home_Exercise_2",
    "section": "",
    "text": "Despite the increasing amount of open data available for public consumption, significant practical research has not yet been conducted to demonstrate how these disparate data sources can be integrated, analyzed, and modeled to support policy-making decisions. There is a general lack of practical research demonstrating how geospatial data science and analytics (GDSA) can be used to support decision-making."
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#objective",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#objective",
    "title": "Take-Home_Exercise_2",
    "section": "",
    "text": "The purpose of this analysis is to conduct a case study to demonstrate the potential value of GDSA to integrate publicly available data from multiple sources to build a spatial interaction model to identify factors influencing public transport urban traffic patterns.\n\n\n\nDerive an analytical hexagon data of 325m (this distance is the perpendicular distance between the centre of the hexagon and its edges) to represent the traffic analysis zone (TAZ).\nWith reference to the time intervals provided in the table below, construct an O-D matrix of commuter flows for a time interval of your choice by integrating Passenger Volume by Origin Destination Bus Stops and Bus Stop Location from LTA DataMall. The O-D matrix must be aggregated at the analytics hexagon level\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the O-D flows of the passenger trips by using appropriate geovisualisation methods (not more than 5 maps).\nDescribe the spatial patterns revealed by the geovisualisation (not more than 100 words per visual).\nAssemble at least three propulsive and three attractiveness variables by using aspatial and geospatial from publicly available sources.\nCompute a distance matrix by using the analytical hexagon data derived earlier.\n\n\n\n\n\nCalibrate spatial interactive models to determine factors affecting urban commuting flows at the selected time interval.\nPresent the modelling results by using appropriate geovisualisation and graphical visualisation methods. (Not more than 5 visuals)\nWith reference to the Spatial Interaction Model output tables, maps and data visualisation prepared, describe the modelling results. (not more than 100 words per visual)."
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#setting-the-analytical-tools",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#setting-the-analytical-tools",
    "title": "Take-Home_Exercise_2",
    "section": "2.1 Setting the Analytical Tools",
    "text": "2.1 Setting the Analytical Tools\nThe code chunk below installs and loads the various packages\n\npacman::p_load(tmap, sf, DT, ggpubr, performance, tidyverse, stplanr)"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#importing-data",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#importing-data",
    "title": "Take-Home_Exercise_2",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nWe will import the data as a first step before proceeding with data cleaning, data wrangling and data exploration for the following:\nPassenger Volume\nPassengerVolume is an aspatial data, we can import the data simply by using the read_csv function from tidyverse package and output it as a tibble dataframe called odbus\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\nRows: 5694297 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBus Stop Location\nBus Stop is a geospatial data in .shp file. We save it as a sf data frame called busstop using the st_read function of the sf package. The data is then geo-referenced to coordinates from the Singapore SVY21 coordinate system (EPSG: 3414)\n\n\nShow the code\nbusstop &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\n\nReading layer `BusStop' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Take-Home_Ex_2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nsub-zone boundary of URA Master Plan 2019\nsub-zone boundary of URA Master Plan 2019 is a geospatial data in .shp file. We save it as a sf data frame called mpsz using the st_read function of the sf package. The data is then geo-referenced to coordinates from the Singapore SVY21 coordinate system (EPSG: 3414)\n\n\nShow the code\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Take-Home_Ex_2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#classify-peak-hours",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#classify-peak-hours",
    "title": "Take-Home_Exercise_2",
    "section": "2.3 Classify peak hours",
    "text": "2.3 Classify peak hours\nAccording to the time interval specified in the task, calculate the passenger travel volume generated at the departure place. Passenger itineraries by origin are saved in 4 data frames according to their respective classifications, namely:\nWeekday morning peak\nWeekday afternoon peak\nWeekend morning peak\nWeekend evening peak\nSave the processed data to a .rds data format file. Output files are saved in the rds subfolder. This is done to reduce load times and keep large raw files from being uploaded to GitHub.\n\n\nShow the code\nweekday_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nShow the code\nweekday_afternoon_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nShow the code\nweekend_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nShow the code\nweekend_evening_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nShow the code\nwrite_rds(weekday_morning_peak, \"data/rds/weekday_morning_peak.rds\")\nweekday_morning_peak &lt;- read_rds(\"data/rds/weekday_morning_peak.rds\")\n\nwrite_rds(weekday_afternoon_peak, \"data/rds/weekday_afternoon_peak.rds\")\nweekday_afternoon_peak &lt;- read_rds(\"data/rds/weekday_afternoon_peak.rds\")\n\nwrite_rds(weekend_morning_peak, \"data/rds/weekend_morning_peak.rds\")\nweekend_morning_peak &lt;- read_rds(\"data/rds/weekend_morning_peak.rds\")\n\nwrite_rds(weekend_evening_peak, \"data/rds/weekend_evening_peak.rds\")\nweekend_evening_peak &lt;- read_rds(\"data/rds/weekend_evening_peak.rds\")"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#passenger-volume",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#passenger-volume",
    "title": "Take-Home_Exercise_2",
    "section": "3.1 Passenger Volume",
    "text": "3.1 Passenger Volume\n\n\nShow the code\nglimpse(odbus)\n\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nSince we plan to use the bus stop code as a unique identifier when joining with other datasets, change it to a factor data type.\n\n\nShow the code\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\nChecking for Duplicates and Missing Data\n\n\nShow the code\nduplicate &lt;- odbus %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\n\n\nShow the code\nsummary(odbus)\n\n\n  YEAR_MONTH          DAY_TYPE         TIME_PER_HOUR     PT_TYPE         \n Length:5694297     Length:5694297     Min.   : 0.00   Length:5694297    \n Class :character   Class :character   1st Qu.:10.00   Class :character  \n Mode  :character   Mode  :character   Median :14.00   Mode  :character  \n                                       Mean   :14.04                     \n                                       3rd Qu.:18.00                     \n                                       Max.   :23.00                     \n                                                                         \n ORIGIN_PT_CODE    DESTINATION_PT_CODE  TOTAL_TRIPS      \n 22009  :  17444   22009  :  17328     Min.   :    1.00  \n 84009  :  16842   84009  :  16808     1st Qu.:    2.00  \n 52009  :  16734   52009  :  16253     Median :    4.00  \n 75009  :  16610   75009  :  16143     Mean   :   20.76  \n 59009  :  14991   59009  :  15134     3rd Qu.:   12.00  \n 46009  :  14642   46009  :  14167     Max.   :36668.00  \n (Other):5597034   (Other):5598464                       \n\n\nThere is no missing data or duplicates."
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#combining-busstop-and-mpsz",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#combining-busstop-and-mpsz",
    "title": "Take-Home_Exercise_2",
    "section": "3.2 Combining Busstop and mpsz",
    "text": "3.2 Combining Busstop and mpsz\nCode chunk below populates the planning subzone code (i.e. SUBZONE_C) of mpsz sf data frame into busstop sf data frame.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) \n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#creating-hexagon-layer",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#creating-hexagon-layer",
    "title": "Take-Home_Exercise_2",
    "section": "3.3 Creating Hexagon layer",
    "text": "3.3 Creating Hexagon layer\nNow, I am going to create a hexagon layer:\n\n# cell size of layer of 250m\narea_honeycomb_grid = st_make_grid(busstop_mpsz, c(650, 650), what = \"polygons\", square = FALSE, crs = 3414)\n\n# To sf and add grid ID\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid)\n\n\nst_write(honeycomb_grid_sf, \"data/geospatial/hexagon.shp\",append=TRUE)\n\nUpdating layer `hexagon' to data source `data/geospatial/hexagon.shp' using driver `ESRI Shapefile'\nUpdating existing layer hexagon\nWriting 2988 features with 0 fields and geometry type Polygon.\n\n\n\nhexagon &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"hexagon\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `hexagon' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Take-Home_Ex_2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 23904 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3320.122 ymin: 26106.82 xmax: 48820.12 ymax: 50499.87\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#combine-hexagon-and-busstop_mpsz",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#combine-hexagon-and-busstop_mpsz",
    "title": "Take-Home_Exercise_2",
    "section": "4.3 Combine Hexagon and Busstop_Mpsz",
    "text": "4.3 Combine Hexagon and Busstop_Mpsz\nNext, we are going to combine the datset busstop_mpsz and hexagon\n\nod_data &lt;- st_join(busstop_mpsz , hexagon,\n            by = c(\"geometry\" = \"geometry\"))"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#combine-peak-data-with-od_data",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#combine-peak-data-with-od_data",
    "title": "Take-Home_Exercise_2",
    "section": "4.4 Combine Peak data with od_data",
    "text": "4.4 Combine Peak data with od_data\n\nod_day_m &lt;- left_join(weekday_morning_peak , od_data,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(weekday_morning_peak, od_data, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5369 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nod_day_a &lt;- left_join(weekday_afternoon_peak , od_data,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(weekday_afternoon_peak, od_data, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5369 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nod_end_m &lt;- left_join(weekend_morning_peak , od_data,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(weekend_morning_peak, od_data, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5369 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nod_end_a &lt;- left_join(weekday_afternoon_peak , od_data,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(weekday_afternoon_peak, od_data, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5369 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nBefore continue, it is a good practice for us to check for duplicating records.\n\n\nShow the code\nduplicate &lt;- od_day_m %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate &lt;- od_day_a %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate &lt;- od_end_m %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate &lt;- od_end_a %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_day_m &lt;- unique(od_day_m)\nod_day_a &lt;- unique(od_day_a)\nod_end_m &lt;- unique(od_end_m)\nod_end_a &lt;- unique(od_end_a)\n\nIt will be a good practice to confirm if the duplicating records issue has been addressed fully.\nNext, we will update od_data data frame with the planning subzone codes\n\nod_day_m &lt;- left_join(od_day_m , od_data,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_day_m, od_data, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5361 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nod_day_a &lt;- left_join(od_day_a , od_data,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_day_a, od_data, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5361 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nod_end_m &lt;- left_join(od_end_m , od_data,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_end_m, od_data, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5361 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nod_end_a &lt;- left_join(od_end_a , od_data,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_end_a, od_data, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 5361 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\nShow the code\nod_day_m &lt;- od_day_m %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nShow the code\nod_day_a &lt;- od_day_a %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(AFTERNOON_PEAK = sum(TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nShow the code\nod_end_m &lt;- od_end_m %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nShow the code\nod_end_a &lt;- od_end_a %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(AFTERNOON_PEAK = sum(TRIPS))\n\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nIt is time to save the output into an rds file format.\n\nwrite_rds(od_day_m, \"data/rds/od_day_m.rds\")\nwrite_rds(od_day_a, \"data/rds/od_day_a.rds\")\nwrite_rds(od_end_m, \"data/rds/od_end_m.rds\")\nwrite_rds(od_end_a, \"data/rds/od_end_a.rds\")\n\n\nod_day_m &lt;- read_rds(\"data/rds/od_day_m.rds\")\nod_day_a &lt;- read_rds(\"data/rds/od_day_a.rds\")\nod_end_m &lt;- read_rds(\"data/rds/od_end_m.rds\")\nod_end_a &lt;- read_rds(\"data/rds/od_end_a.rds\")"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#visualising-spatial-interaction",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#visualising-spatial-interaction",
    "title": "Take-Home_Exercise_2",
    "section": "5 Visualising Spatial Interaction",
    "text": "5 Visualising Spatial Interaction"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#removing-intra-zonal-flows",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#removing-intra-zonal-flows",
    "title": "Take-Home_Exercise_2",
    "section": "5.1 Removing intra-zonal flows",
    "text": "5.1 Removing intra-zonal flows\nI will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.\n\nod_day_m &lt;- od_day_m[od_day_m$ORIGIN_SZ!=od_day_m$DESTIN_SZ,]\nod_day_a &lt;- od_day_a[od_day_a$ORIGIN_SZ!=od_day_a$DESTIN_SZ,]\nod_end_m &lt;- od_end_m[od_end_m$ORIGIN_SZ!=od_end_m$DESTIN_SZ,]\nod_end_a &lt;- od_end_a[od_end_a$ORIGIN_SZ!=od_end_a$DESTIN_SZ,]"
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#creating-desire-lines",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#creating-desire-lines",
    "title": "Take-Home_Exercise_2",
    "section": "5.2 Creating desire lines",
    "text": "5.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\nflowLine_day_m &lt;- od2line(flow = od_day_m, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\nflowLine_day_a &lt;- od2line(flow = od_day_a, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\nflowLine_end_m &lt;- od2line(flow = od_end_m, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\nflowLine_end_a &lt;- od2line(flow = od_end_a, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points."
  },
  {
    "objectID": "Take-Home_Ex_2/Take-Home_Ex_2.html#visualising-the-desire-lines",
    "href": "Take-Home_Ex_2/Take-Home_Ex_2.html#visualising-the-desire-lines",
    "title": "Take-Home_Exercise_2",
    "section": "5.3 Visualising the desire lines",
    "text": "5.3 Visualising the desire lines\nTo visualise the resulting desire lines, the code chunk below is used.\n\n\nShow the code\nmapex &lt;- st_bbox(hexagon)\n\ntm_shape(mpsz, bbox = mapex) +\n  tm_polygons() +\ntm_shape(flowLine_day_m) +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           col = \"blue\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.8) +\ntm_layout(outer.margins = c(0, 0, 0., 0), \n          legend.position = c(\"right\", \"bottom\"),  \n          legend.frame = TRUE,\n          legend.outside = TRUE) \n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.53. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\nShow the code\nmapex &lt;- st_bbox(hexagon)\ntm_shape(mpsz, bbox = mapex) +\n  tm_polygons() +\ntm_shape(flowLine_day_a) +  \n  tm_lines(lwd = \"AFTERNOON_PEAK\",\n           col = \"purple\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.8) +\ntm_layout(outer.margins = c(0, 0, 0., 0), \n          legend.position = c(\"right\", \"bottom\"),  \n          legend.frame = TRUE,\n          legend.outside = TRUE) \n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.53. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\nShow the code\nmapex &lt;- st_bbox(hexagon)\ntm_shape(mpsz, bbox = mapex) +\n  tm_polygons() +  \ntm_shape(flowLine_end_m) +  \n  tm_lines(lwd = \"MORNING_PEAK\",\n           col = \"red\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.8) +\ntm_layout(outer.margins = c(0, 0, 0., 0), \n          legend.position = c(\"right\", \"bottom\"),  \n          legend.frame = TRUE,\n          legend.outside = TRUE) \n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.39. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\nShow the code\nmapex &lt;- st_bbox(hexagon)\ntm_shape(mpsz, bbox = mapex) +\n  tm_polygons() +  \ntm_shape(flowLine_end_a) +  \n  tm_lines(lwd = \"AFTERNOON_PEAK\",\n           col = \"black\",  \n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.8) +\ntm_layout(outer.margins = c(0, 0, 0., 0), \n          legend.position = c(\"right\", \"bottom\"),  \n          legend.frame = TRUE,\n          legend.outside = TRUE) \n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.53. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\n\nShow the code\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine_day_m %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           col = \"blue\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 1)\n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n\n\nShow the code\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine_day_a %&gt;%  \n  filter(AFTERNOON_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"AFTERNOON_PEAK\",\n           col = \"purple\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 1)\n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n\n\nShow the code\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine_end_m %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           col = \"red\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 1)\n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.58. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\nShow the code\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine_end_a %&gt;%  \n  filter(AFTERNOON_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"AFTERNOON_PEAK\",\n           col = \"black\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 1)\n\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute spatial weights using R. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.Getting Started"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#computing-queen-contiguity-based-neighbours",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "5.1 Computing (QUEEN) contiguity based neighbours",
    "text": "5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nDisplay the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#creating-rook-contiguity-based-neighbours",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "5.2 Creating (ROOK) contiguity based neighbours",
    "text": "5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "5.3 Visualising contiguity weights",
    "text": "5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nA check if things are formatted correctly\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n5.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#determine-the-cut-off-distance",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "6.1 Determine the cut-off distance",
    "text": "6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "6.2 Computing fixed distance weight matrix",
    "text": "6.2 Computing fixed distance weight matrix\nCompute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nAns: On average, each region is connected to approximately 3.68 other regions. This suggests the average connectivity or the average number of neighboring regions for each individual region in this network.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.8)\n\n\n\n\n** The red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "6.3 Computing adaptive distance weight matrix",
    "text": "6.3 Computing adaptive distance weight matrix\nThe code below shows that it is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nDisplay\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n** To note: each county has six neighbours\n\n6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "7.1 Row-standardised weights matrix",
    "text": "7.1 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "8.1 Spatial lag with row-standardized weights",
    "text": "8.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "8.2 Spatial lag as a sum of neighboring values",
    "text": "8.2 Spatial lag as a sum of neighboring values\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nLet us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-window-average",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-window-average",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "8.3 Spatial window average",
    "text": "8.3 Spatial window average\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nConvert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nThe code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-window-sum",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2.html#spatial-window-sum",
    "title": "Hands-on Exercise 2: Spatial Weights and Applications",
    "section": "8.4 Spatial window sum",
    "text": "8.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord's Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#setting-the-analytical-tools",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#setting-the-analytical-tools",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Setting the Analytical Tools",
    "text": "Setting the Analytical Tools\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Import shapefile into r environment",
    "text": "Import shapefile into r environment\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Import csv file into r environment",
    "text": "Import csv file into r environment\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#performing-relational-join",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#performing-relational-join",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Performing relational join",
    "text": "Performing relational join\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Row-standardised weights matrix",
    "text": "Row-standardised weights matrix\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#global-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Moran’s I",
    "text": "Global Spatial Autocorrelation: Moran’s I\nIn this section, I will learn how to perform Moran’s I statistics testing by using moran.test() of spdep."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#marons-i-test",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#marons-i-test",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Maron’s I test",
    "text": "Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n** Conclusion\nThe Moran’s I test suggests strong evidence against the null hypothesis of spatial randomness (p-value = 1.095e-06). The Moran’s I statistic of 0.3007 indicates a significant positive spatial autocorrelation in the variable ‘GDPPC’ within the study area. Areas in this region with similar GDPPC values tend to be spatially clustered or adjacent to each other more often than expected by random chance.\n\nComputing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nConclusion\nA permutation test of the Moran’s I statistic rejects the null hypothesis of spatial randomness. The observed Moran’s I value (0.30075) is among the highest ranks of simulated values, while the small p-value (0.001) indicates that the value is significantly greater than what would be expected by chance alone. Therefore, the hypothesis that there is a significant positive spatial autocorrelation of the “GDPPC” variable in the study area is supported. Regions with similar GDPPC values tend to cluster spatially or are adjacent to each other.\n\n\nVisualising Monte Carlo Moran’s I\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#global-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#global-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Geary’s c",
    "text": "Global Spatial Autocorrelation: Geary’s c\nIn this section, you will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\nGeary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n** Conclusion\nGiven the low p-value, we can conclude that there is significant evidence to reject the null hypothesis of spatial randomness. We have sufficient evidence to conclude that the alternative hypothesis that there is spatial autocorrelation present in the variable “hunan$GDPPC.” Moreover, the Geary C statistic being substantially lower than the expected value under the null hypothesis further supports this conclusion.\n\n\nComputing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualising the Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n* Observation\nSkewed distribution that is of left skewed. It peaks at 1.05"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Compute Moran’s I correlogram",
    "text": "Compute Moran’s I correlogram\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#compute-gearys-c-correlogram-and-plot",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Compute Geary’s C correlogram and plot",
    "text": "Compute Geary’s C correlogram and plot\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#computing-local-morans-i",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#computing-local-morans-i",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Computing local Moran's I",
    "text": "Computing local Moran's I\nTo compute local Moran's I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran's I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nMapping the local Moran’s I\nThe code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\nMapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nMapping local Moran’s I p-values\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Plotting Moran scatterplot",
    "text": "Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Plotting Moran scatterplot with standardised variable",
    "text": "Plotting Moran scatterplot with standardised variable\nScaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes",
    "text": "Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#plotting-lisa-map",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#plotting-lisa-map",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Plotting LISA map",
    "text": "Plotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Getis and Ord’s G-Statistics",
    "text": "Getis and Ord’s G-Statistics\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#deriving-distance-based-weight-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#deriving-distance-based-weight-matrix",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Deriving distance-based weight matrix",
    "text": "Deriving distance-based weight matrix\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\nDeriving the centroid\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\nComputing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#gi-statistics-using-fixed-distance",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Gi statistics using fixed distance",
    "text": "Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename()."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#mapping-gi-values-with-fixed-distance-weights",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#mapping-gi-values-with-fixed-distance-weights",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Mapping Gi values with fixed distance weights",
    "text": "Mapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#gi-statistics-using-adaptive-distance",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Gi statistics using adaptive distance",
    "text": "Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2b.html#mapping-gi-values-with-adaptive-distance-weights",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2b.html#mapping-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Exercise 2.3: Local Measures of Spatial Autocorrelation",
    "section": "Mapping Gi values with adaptive distance weights",
    "text": "Mapping Gi values with adaptive distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord's Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#setting-the-analytical-tools",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#setting-the-analytical-tools",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Setting the Analytical Tools",
    "text": "Setting the Analytical Tools\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Import shapefile into r environment",
    "text": "Import shapefile into r environment\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Hands-on_Ex_2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Import csv file into r environment",
    "text": "Import csv file into r environment\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#performing-relational-join",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#performing-relational-join",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Performing relational join",
    "text": "Performing relational join\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nI prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Row-standardised weights matrix",
    "text": "Row-standardised weights matrix\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#global-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Moran’s I",
    "text": "Global Spatial Autocorrelation: Moran’s I\nIn this section, I will learn how to perform Moran’s I statistics testing by using moran.test() of spdep."
  },
  {
    "objectID": "Hands-on_Ex_2/Hands-on_Ex_2a.html#marons-i-test",
    "href": "Hands-on_Ex_2/Hands-on_Ex_2a.html#marons-i-test",
    "title": "Hands-on Exercise 2.1: Global Measures of Spatial Autocorrelation",
    "section": "Maron’s I test",
    "text": "Maron’s I test\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n** Conclusion\nThe Moran’s I test suggests strong evidence against the null hypothesis of spatial randomness (p-value = 1.095e-06). The Moran’s I statistic of 0.3007 indicates a significant positive spatial autocorrelation in the variable ‘GDPPC’ within the study area. Areas in this region with similar GDPPC values tend to be spatially clustered or adjacent to each other more often than expected by random chance.\n\nComputing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n** Conclusion\nThe permutation test for Moran’s I statistic indicates strong evidence against the null hypothesis of spatial randomness. The observed Moran’s I value (0.30075) falls within the highest ranks of the simulated values, and the small p-value (0.001) suggests that this value is significantly greater than what would be expected by chance alone. Therefore, it supports the conclusion that there is a significant positive spatial autocorrelation in the ‘GDPPC’ variable within the study area. Areas with similar GDPPC values tend to be spatially clustered or adjacent to each other more often than expected by random chance.\n\n\nVisualising Monte Carlo Moran’s I\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n** Observation\nSkewed distribution that is of right skewed. It peaks at -0.05\nPlot values using ggplot:\n\nbperm &lt;- list(\n  res = rnorm(1000),\n  statistic = 0.30075\n)\n\n\nplot_data &lt;- data.frame(\n  Simulation = 1:length(bperm$res),\n  Moran_I = bperm$res\n)\n\n\nplot &lt;- ggplot(plot_data, aes(x = Simulation, y = Moran_I)) +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_hline(yintercept = bperm$statistic, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Permutation Test for Moran's I\",\n    x = \"Simulation\",\n    y = \"Moran's I Value\"\n  ) +\n  theme_minimal()\n\nplot\n\n\n\n\n\n\nGlobal Spatial Autocorrelation: Geary’s\nI will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\nGeary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n** Conclusion\nGiven the low p-value, we can conclude that there is significant evidence to reject the null hypothesis of spatial randomness. We have sufficient evidence to conclude that the alternative hypothesis that there is spatial autocorrelation present in the variable “hunan$GDPPC.” Moreover, the Geary C statistic being substantially lower than the expected value under the null hypothesis further supports this conclusion.\n\n\nComputing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n**Conclusion\nThe very low p-value (0.001) suggests strong evidence against the null hypothesis of spatial randomness. Instead, it supports the alternative hypothesis that there is significant spatial autocorrelation present in the variable “hunan$GDPPC.”\nFurthermore, the observed rank of 1 among the 1000 simulations indicates that your observed statistic is at the extreme end of the simulated distribution. This strengthens the evidence that the observed spatial autocorrelation is significantly higher than what would be expected by chance.\n\n\nVisualising the Monte Carlo Geary’s C\nWe plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n** Observation\nSkewed distribution that is of left skewed. It peaks at 1.05"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban transportation and infrastructure become digitized, the resulting data sets can be used as a framework for crafting patterns of movement in space and time. These large amounts of motion data collected may contain structures and patterns that provide useful information about the characteristics of the measured phenomena. The identification, analysis and comparison of these patterns will provide deeper insights into how people move and behave within cities. These understandings will potentially contribute to better urban management and provide useful information to private and public sector urban transport service providers to make informed decisions to gain a competitive advantage.\n\n\nExploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThis study mainly uses three methods：\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualization methods,\nDescribe the spatial patterns revealed by the geovisualization (not more than 200 words per visual).\n\n\n\n\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualization prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).\n\n\n\n\n\nThe focus of this study will be Singapore. Singapore’s public transport system is renowned for its efficient, clean, safe and timely services. The city has a comprehensive digital public transportation network that is optimized through advanced information technology and big data analytics to improve operational efficiency and passenger experience.\nSingapore’s urban infrastructure, such as utilities and roads, is also highly digitalized, using sensors, the Internet of Things (IoT) and other advanced technologies to monitor and manage city operations. For example, through vehicles equipped with GPS and RFID, traffic flows and patterns can be tracked, which helps in real-time traffic management and planning.\nThese digitalization measures enable Singapore to make important progress in improving the efficiency of public services, promoting sustainable development and enhancing the quality of life of residents."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#objectives-and-methods",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#objectives-and-methods",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThis study mainly uses three methods：\n\n\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualization methods,\nDescribe the spatial patterns revealed by the geovisualization (not more than 200 words per visual).\n\n\n\n\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).\n\n\n\n\nWith reference to the passenger trips by origin at the hexagon level for the four time intervals given above:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nPrepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05).\nWith reference to the EHSA maps and data visualization prepared, describe the spatial patterns reveled. (not more than 250 words per cluster)."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#study-area",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#study-area",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "The focus of this study will be Singapore. Singapore’s public transport system is renowned for its efficient, clean, safe and timely services. The city has a comprehensive digital public transportation network that is optimized through advanced information technology and big data analytics to improve operational efficiency and passenger experience.\nSingapore’s urban infrastructure, such as utilities and roads, is also highly digitalized, using sensors, the Internet of Things (IoT) and other advanced technologies to monitor and manage city operations. For example, through vehicles equipped with GPS and RFID, traffic flows and patterns can be tracked, which helps in real-time traffic management and planning.\nThese digitalization measures enable Singapore to make important progress in improving the efficiency of public services, promoting sustainable development and enhancing the quality of life of residents."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#setting-the-analytical-tools",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#setting-the-analytical-tools",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.1 Setting the Analytical Tools",
    "text": "2.1 Setting the Analytical Tools\nThe code chunk below installs and loads sf, sfdep, magrittr, tidyverse, tmap, knitr, RColorBrewer, viridis packages into R environment. pacman() is a R package management tool.\n\npacman::p_load(sf, sfdep, magrittr, tidyverse, tmap, knitr, RColorBrewer, viridis, dplyr)"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#importing-data",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#importing-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nWe will import the data as a first step before proceeding with data cleaning, data wrangling and data exploration for the following:\nPassenger Volume\nPassengerVolume is an aspatial data, we can import the data simply by using the read_csv function from tidyverse package and output it as a tibble dataframe called odbus\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\nRows: 5694297 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBus Stop Location\nBus Stop is a geospatial data in .shp file. We save it as a sf data frame called busstop using the st_read function of the sf package. The data is then geo-referenced to coordinates from the Singapore SVY21 coordinate system (EPSG: 3414)\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `BusStop' from data source \n  `/Users/WangYuhui/Desktop/SMU/Special_Term/ISSS624-G1-Applied-Geospatial-Analytics/ISSS624/Take-Home_Ex_1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#data-wrangling",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#data-wrangling",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Passenger Volume\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nSince we plan to use the bus stop code as a unique identifier when joining with other datasets, change it to a factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nChecking for Duplicates and Missing Data\n\nduplicate &lt;- odbus %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\n\nsummary(odbus)\n\n  YEAR_MONTH          DAY_TYPE         TIME_PER_HOUR     PT_TYPE         \n Length:5694297     Length:5694297     Min.   : 0.00   Length:5694297    \n Class :character   Class :character   1st Qu.:10.00   Class :character  \n Mode  :character   Mode  :character   Median :14.00   Mode  :character  \n                                       Mean   :14.04                     \n                                       3rd Qu.:18.00                     \n                                       Max.   :23.00                     \n                                                                         \n ORIGIN_PT_CODE    DESTINATION_PT_CODE  TOTAL_TRIPS      \n 22009  :  17444   22009  :  17328     Min.   :    1.00  \n 84009  :  16842   84009  :  16808     1st Qu.:    2.00  \n 52009  :  16734   52009  :  16253     Median :    4.00  \n 75009  :  16610   75009  :  16143     Mean   :   20.76  \n 59009  :  14991   59009  :  15134     3rd Qu.:   12.00  \n 46009  :  14642   46009  :  14167     Max.   :36668.00  \n (Other):5597034   (Other):5598464                       \n\n\nThere is no missing data or duplicates."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#classify-peak-hours",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#classify-peak-hours",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.4 Classify peak hours",
    "text": "2.4 Classify peak hours\nAccording to the time interval specified in the task, calculate the passenger travel volume generated at the departure place. Passenger itineraries by origin are saved in 4 data frames according to their respective classifications, namely:\nWeekday morning peak\nWeekday afternoon peak\nWeekend morning peak\nWeekend evening peak\nSave the processed data to a .rds data format file. Output files are saved in the rds subfolder. This is done to reduce load times and keep large raw files from being uploaded to GitHub.\n\n\nShow the code\nweekday_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekday_afternoon_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekend_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekend_evening_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nwrite_rds(weekday_morning_peak, \"data/rds/weekday_morning_peak.rds\")\nweekday_morning_peak &lt;- read_rds(\"data/rds/weekday_morning_peak.rds\")\n\nwrite_rds(weekday_afternoon_peak, \"data/rds/weekday_afternoon_peak.rds\")\nweekday_afternoon_peak &lt;- read_rds(\"data/rds/weekday_afternoon_peak.rds\")\n\nwrite_rds(weekend_morning_peak, \"data/rds/weekend_morning_peak.rds\")\nweekend_morning_peak &lt;- read_rds(\"data/rds/weekend_morning_peak.rds\")\n\nwrite_rds(weekend_evening_peak, \"data/rds/weekend_evening_peak.rds\")\nweekend_evening_peak &lt;- read_rds(\"data/rds/weekend_evening_peak.rds\")"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#creating-hexagon-data",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#creating-hexagon-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.5 Creating Hexagon Data",
    "text": "2.5 Creating Hexagon Data\nCreate Hexagon Dataset from busstop\n\nhexagon = st_make_grid(busstop, c(250, 250), what = \"polygons\", square = FALSE)\nhexagon_sf = st_sf(hexagon) %&gt;%\n  mutate(grid_id = 1:length(lengths(hexagon)))\n\nExamine the Grid\n\nhexagon_sf$coll &lt;- lengths(st_intersects(hexagon_sf, busstop))\nprint(n_distinct(hexagon_sf$grid_id))\n\n[1] 22134\n\nprint(sum(hexagon_sf$coll == 0))\n\n[1] 19003\n\nsummary(hexagon_sf$coll)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.2332  0.0000  5.0000 \n\n\nThere are 22134 grids and 19003 grids with zero bus stops, a max of 5 bus stops per grid.\nDelete hexagonal data with zero bus stops\n\nhexagon_sf = filter(hexagon_sf, coll &gt; 0)\nwrite_rds(hexagon_sf, \"data/rds/hexagon_sf.rds\")\nhexagon_sf &lt;- read_rds(\"data/rds/hexagon_sf.rds\")"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.6 Visualizing",
    "text": "2.6 Visualizing\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nmap_busstopcounts = tm_shape(hexagon_sf) +\n  tm_fill(\n    col = \"coll\",\n    palette = c(\"grey\",rev(viridis(6))),\n    breaks = c(0, 1, 2, 3, 4, 5),\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 1,\n    popup.vars = c(\n      \"Number of collisions: \" = \"coll\"\n    ),\n    popup.format = list(\n      coll = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"black\", lwd = 0.2)\n\nmap_busstopcounts\n\n\n\n\n\nFrom the picture we can see:\nThere is no bus station in the central area, probably because there is a reservoir.\nThere are very few bus stops in the northwest, probably because there is a farm."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#combining-the-data",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#combining-the-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2.7 Combining the Data",
    "text": "2.7 Combining the Data\n\n\nShow the code\n# Define a function to merge and summarize data\nmerge_and_summarize &lt;- function(time_peak_data, busstop_hexagon, hexagon_sf) {\n  join_list &lt;- left_join(time_peak_data, busstop_hexagon, by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n    rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_GRID = grid_id) %&gt;%\n    group_by(ORIGIN_GRID) %&gt;%\n    summarise(TOT_TRIPS = sum(TRIPS))\n\n  join_geometry &lt;- left_join(hexagon_sf, join_list, by = c(\"grid_id\" = \"ORIGIN_GRID\"))\n  return(join_geometry)\n}\n\n# List to store different time period data\ntime_peaks &lt;- list(\n  weekday_morning_peak,\n  weekday_afternoon_peak,\n  weekend_morning_peak,\n  weekend_evening_peak\n)\n\n# Merge bus stop and hexagonal grid\nbusstop_hexagon &lt;- st_intersection(busstop, hexagon_sf) %&gt;%\n  select(BUS_STOP_N, grid_id) %&gt;%\n  st_drop_geometry\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nShow the code\n# Apply the function to each time period\nresults &lt;- lapply(time_peaks, function(data) merge_and_summarize(data, busstop_hexagon, hexagon_sf))\n\n# Save the results in RDS format\nfile_names &lt;- c(\"weekday_morning_peak_join_geometry.rds\",\n                \"weekday_afternoon_peak_join_geometry.rds\",\n                \"weekend_morning_peak_join_geometry.rds\",\n                \"weekend_evening_peak_join_geometry.rds\")\n\nfor (i in seq_along(results)) {\n  write_rds(results[[i]], paste0(\"data/rds/\", file_names[i]))\n}"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#distribution-of-total-trips-and-trips-per-bus-stop",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#distribution-of-total-trips-and-trips-per-bus-stop",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "3.1 Distribution of total trips and trips per bus stop",
    "text": "3.1 Distribution of total trips and trips per bus stop\n\n\nShow the code\nrds_path &lt;- \"data/rds/\"\nweekday_morning_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekday_morning_peak_join_geometry.rds\"))\nweekday_afternoon_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekday_afternoon_peak_join_geometry.rds\"))\nweekend_morning_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekend_morning_peak_join_geometry.rds\"))\nweekend_evening_peak_join_geometry &lt;- readRDS(paste0(rds_path, \"weekend_evening_peak_join_geometry.rds\"))\n\n\n\n\ncombined_data &lt;- bind_rows(\n  weekday_morning_peak_join_geometry %&gt;% mutate(period = \"Weekday Morning Peak\"),\n  weekday_afternoon_peak_join_geometry %&gt;% mutate(period = \"Weekday Afternoon Peak\"),\n  weekend_morning_peak_join_geometry %&gt;% mutate(period = \"Weekend Morning Peak\"),\n  weekend_evening_peak_join_geometry %&gt;% mutate(period = \"Weekend Evening Peak\")\n)\n\n\n# Plot combined data\nggplot(data = combined_data, \n       aes(x = as.numeric(`TOT_TRIPS`))) +\n  geom_histogram(bins = 20, \n                 color = \"blue\", \n                 fill = \"blue\") +\n  facet_wrap(~period, scales = \"free_y\") +\n  labs(title = \"Distribution of Passenger Trips during Different Time Periods\",\n       x = \"Total Trips\",\n       y = \"Frequency\")\n\n\nWarning: Removed 337 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\nShow the code\nlibrary(ggplot2)\n\ncombined_dsitribution &lt;- combined_data %&gt;%\n  mutate(`trips_per_busstop` = (`TOT_TRIPS` / coll))\n\nggplot(data = combined_dsitribution, aes(x = as.numeric(`trips_per_busstop`))) +\n  geom_histogram(bins = 20, color = \"blue\", fill = \"blue\") +\n  facet_wrap(~period, scales = \"free_y\") +\n  labs(title = \"Distribution of Passenger Trips during Different Time Periods\",\n       x = \"Total Trips Per BusStop\",\n       y = \"Frequency\") +\n  theme_minimal() \n\n\nWarning: Removed 337 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#distribution-across-4-time-periods",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#distribution-across-4-time-periods",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "3.2 Distribution Across 4 Time Periods",
    "text": "3.2 Distribution Across 4 Time Periods\n\n\nShow the code\nggplot(combined_data, aes(x = factor(period), y = TOT_TRIPS)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = \"blue\") +\n  labs(title = \"Distribution Across 4 Time Periods\",\n       x = \"Time Period\",\n       y = \"Total Trips\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\nWarning: Removed 337 rows containing missing values (`geom_bar()`).\n\n\n\n\n\nThrough the above analysis, it is found that the number of trips during the morning peak on weekdays is the largest, followed by the afternoon peak on weekdays, the morning peak on weekends, and finally the evening peak on weekends.\nPublic transportation authorities can use this information to better allocate personnel and public transportation resources."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#calculating-adaptive-distance-weights",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#calculating-adaptive-distance-weights",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.1 Calculating adaptive distance weights",
    "text": "5.1 Calculating adaptive distance weights\nBecause the minimum, median, mean, and 75th percentile are all 250 . Therefore we set k=1 when generating weights.\n\ngeo &lt;- sf::st_geometry(hexagon_sf)\nneighbour &lt;- st_knn(geo, longlat = TRUE)\n\n! Polygon provided. Using point on surface.\n\ndists &lt;- unlist(st_nb_dists(geo, neighbour))\n\n! Polygon provided. Using point on surface.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  250.0   250.0   250.0   259.6   250.0  4250.0 \n\n\n\n\nShow the code\nprocess_data &lt;- function(data, hexagon) {\n  data %&gt;%\n    mutate(TOT_TRIPS = replace_na(TOT_TRIPS, 0), \n           neighbour = st_knn(hexagon, k = 1),\n           wt = st_weights(neighbour, style = \"W\", allow_zero = TRUE),\n           .before = 1)\n}\nwm_q_1 &lt;- process_data(weekday_morning_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface.\n\n\nShow the code\nwm_q_2 &lt;- process_data(weekday_afternoon_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface.\n\n\nShow the code\nwm_q_3 &lt;- process_data(weekend_morning_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface.\n\n\nShow the code\nwm_q_4 &lt;- process_data(weekend_evening_peak_join_geometry, hexagon)\n\n\n! Polygon provided. Using point on surface."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#calculating-local-morans-i-space-autocorrelation-statistics",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#calculating-local-morans-i-space-autocorrelation-statistics",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.2 Calculating local Moran’s I space autocorrelation statistics",
    "text": "5.2 Calculating local Moran’s I space autocorrelation statistics\nThe analysis focuses on the spatial autocorrelation of the variable TOT_TRIPS in each dataset, using the local_moran function for 99 simulations.\nMoran’s I spatial autocorrelation statistic is calculated to evaluate whether nearby observations exhibit similar total travel values, revealing spatial patterns and clustering.\n\n\nShow the code\ncompute_local_moran_I &lt;- function(df) {\n  df %&gt;% \n    mutate(local_moran = local_moran(TOT_TRIPS, neighbour, wt, nsim = 99), .before = 1) %&gt;%\n    unnest(local_moran)\n}\n\n# List of data frames\nwm_qs &lt;- list(wm_q_1, wm_q_2, wm_q_3, wm_q_4)\n\n# Apply the function to each data frame\nlisa_results &lt;- lapply(wm_qs, compute_local_moran_I)\n\nlisa_1 &lt;- lisa_results[[1]]\nlisa_2 &lt;- lisa_results[[2]]\nlisa_3 &lt;- lisa_results[[3]]\nlisa_4 &lt;- lisa_results[[4]]"
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing-1",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing-1",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.3 visualizing",
    "text": "5.3 visualizing\nIn the following code chunk, a partitioned chart is created based on local Moran’s I values. Positive Local Moran’s I values indicate a feature’s membership in a cluster, while negative values indicate that the feature is an outlier. Areas in various shades of green indicate their membership in one or more clusters.\nHowever, relying solely on the local Moran score is not sufficient to describe spatial clustering, as it cannot provide information about whether the total number of passengers’ trips is high or low and whether the test results are statistically significant. We need to continue analyzing only areas where total passenger trips have statistically significant values.\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekday morning\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_2) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekday afternoon\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_3) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekend morning\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_4) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(6)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekend afternoon\",\n            main.title.size = 1.2, main.title.position = \"center\") +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing-p-value-of-local-morans-i",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing-p-value-of-local-morans-i",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.4 visualizing p-value of local Moran’s I",
    "text": "5.4 visualizing p-value of local Moran’s I\nIn the following code chunk below, only statistically significant local Moran’s I values (p_ii_sim &lt; 0.05) are visualized.\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekday morning\",\n            main.title.size = 1.2,\n            main.title.position = \"center\" ) +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_2) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekday afternoon\",\n            main.title.size = 1.2,\n            main.title.position = \"center\") +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_3) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekend morning\",\n            main.title.size = 1.2,\n            main.title.position = \"center\") +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_4) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(6)), \"white\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"NA\")) + \n  tm_borders(alpha = 0.2) +\n  tm_layout(main.title = \"p-value of local Moran I in weekend afternoon\",\n            main.title.size = 1.2,\n            main.title.position = \"center\") +\n  tmap_style(\"natural\")\n\n\ntmap style set to \"natural\"\n\n\nother available styles are: \"white\", \"gray\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing-lisa-map",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#visualizing-lisa-map",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.5 Visualizing LISA map",
    "text": "5.5 Visualizing LISA map\nIn the following code chunk, LISA divides each region into four groups:\nHigh - High means that a grid with a high number of initial trips is next to other grids with a high number of initial trips.\nHigh-Low means grids with more initial trips are next to other grids with fewer initial trips\nLow - Low means that a grid with a low number of initial strokes is next to other grids with a low number of initial strokes\nLow-High means that grids with fewer initial trips are located next to other grids with more initial trips.\n\n5.5.1 Weekday morning peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_1  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n5.5.2 Weekday afternoon peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_2  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n5.5.3 Weekend morning peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_3  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n5.5.4 Weekend afternoon peak\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nlisa_sig &lt;- lisa_4  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(4))) + \n  tm_borders(alpha = 0)+\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Take-Home_Ex_1/Take-Home_Ex_1.html#conclusion",
    "href": "Take-Home_Ex_1/Take-Home_Ex_1.html#conclusion",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5.6 Conclusion",
    "text": "5.6 Conclusion\nHigh-High: In these areas, places with high travel demand are often close to each other, forming obvious travel hotspots. These hotspots may correspond to business centers, residential areas, or other places where activity is concentrated.\nLow-Low: Areas with low travel demand are relatively scattered and do not form large continuous low-demand areas. These may be more remote or inaccessible areas.\nHigh-Low: Represents areas adjacent to high travel areas but with low travel demand. This can happen at the edges of busy areas, or in areas where travel demand has dropped for specific reasons, such as transport planning or geographical constraints.\nLow-High: Indicates that although some areas have low travel demand, they are close to areas with concentrated travel demand. This may be due to superior geographical location but underdevelopment.\nAs can be seen from the four pictures above, the High-Low and Low-High areas are mainly located in the northeast and south-central part, indicating that there is still room for improvement in the public transportation planning of these two areas."
  }
]